# ‚ùÑÔ∏è Snowflake ‚Äî Chapitre : Charger les Donn√©es

> **Niveau** : D√©butant ‚Üí Interm√©diaire | **Version** : 2024  
> **Objectif** : Ma√Ætriser tous les m√©canismes de chargement Snowflake, du fichier local au pipeline GCS/S3/Azure en production.

---

## üìã Sommaire

1. [Vue d'ensemble & Architecture](#1-vue-densemble--architecture)
2. [Cr√©er la structure de donn√©es](#2-cr√©er-la-structure-de-donn√©es)
3. [Les Stages : zone de transit](#3-les-stages--zone-de-transit)
4. [File Formats : d√©crire vos fichiers](#4-file-formats--d√©crire-vos-fichiers)
5. [COPY INTO : chargement en masse](#5-copy-into--chargement-en-masse)
6. [Workflow complet GCS ‚Üí Snowflake](#6-workflow-complet-gcs--snowflake)
7. [Chargement INSERT (petits volumes)](#7-chargement-insert-petits-volumes)
8. [Snowpipe : ingestion continue](#8-snowpipe--ingestion-continue)
9. [PUT & GET : CLI SnowSQL](#9-put--get--cli-snowsql)
10. [Formats de fichiers support√©s](#10-formats-de-fichiers-support√©s)
11. [üî¥ Dictionnaire des erreurs communes](#11--dictionnaire-des-erreurs-communes)
12. [‚úÖ Checklist & Bonnes pratiques](#12--checklist--bonnes-pratiques)

---

## 1. Vue d'ensemble & Architecture

### 1.1 Les 3 grandes m√©thodes

| M√©thode | Cas d'usage | Latence | Complexit√© |
|---|---|---|---|
| **COPY INTO** (Batch) | Fichiers en masse (CSV, JSON, Parquet‚Ä¶) | Minutes | ‚≠ê Faible |
| **Snowpipe** (Streaming) | Ingestion continue / near-realtime | Secondes | ‚≠ê‚≠ê Moyenne |
| **PUT + COPY** (CLI) | Dev/test, uploads manuels | Variable | ‚≠ê Faible |

### 1.2 Architecture globale

```mermaid
flowchart LR
    subgraph SOURCES["üóÇÔ∏è Sources de donn√©es"]
        A[Fichiers locaux\n.csv .json .parquet]
        B[GCS Bucket]
        C[S3 Bucket]
        D[Azure Blob]
    end

    subgraph TRANSIT["üöâ Zone de Transit"]
        E[Internal Stage\n@~ / @%table / @named]
        F[External Stage\n@gcs_stage / @s3_stage]
    end

    subgraph SNOWFLAKE["‚ùÑÔ∏è Snowflake"]
        G[File Format\nd√©crit la structure]
        H[COPY INTO\ncharge en masse]
        I[Table Snowflake]
    end

    A -->|PUT via SnowSQL| E
    B -->|Storage Integration| F
    C -->|Storage Integration| F
    D -->|Storage Integration| F
    E --> G
    F --> G
    G --> H
    H --> I

    style SOURCES fill:#1A3A5C,color:#fff
    style TRANSIT fill:#2E75B6,color:#fff
    style SNOWFLAKE fill:#29B5E8,color:#fff
```

### 1.3 Flux de chargement simplifi√© (sch√©ma mental)

```mermaid
flowchart LR
    A["‚òÅÔ∏è Cloud Storage\nGCS / S3 / Azure"] --> B["üîê Storage Integration\nPermet l'acc√®s IAM"]
    B --> C["üöâ External Stage\nPointeur vers le bucket"]
    C --> D["üìÑ File Format\nD√©crit CSV/JSON/Parquet"]
    D --> E["üì• COPY INTO\nCharge les donn√©es"]
    E --> F["üóÉÔ∏è Table Snowflake"]

    style A fill:#4285F4,color:#fff
    style B fill:#EA4335,color:#fff
    style C fill:#FBBC04,color:#000
    style D fill:#34A853,color:#fff
    style E fill:#29B5E8,color:#fff
    style F fill:#1A3A5C,color:#fff
```

üìñ **Doc officielle** : [Data Loading Overview](https://docs.snowflake.com/fr/user-guide/data-load-overview)

---

## 2. Cr√©er la Structure de Donn√©es

Avant de charger, il faut cr√©er la destination.

### 2.1 Cr√©er Database, Schema, Table

```sql
-- ‚ë† Cr√©er la base de donn√©es
CREATE DATABASE IF NOT EXISTS HEALTH_APP
  COMMENT = 'Base principale application sant√©';

-- ‚ë° Cr√©er le sch√©ma
CREATE SCHEMA IF NOT EXISTS HEALTH_APP.RAW
  COMMENT = 'Donn√©es brutes avant transformation';

-- ‚ë¢ S√©lectionner le contexte
USE DATABASE HEALTH_APP;
USE SCHEMA RAW;

-- ‚ë£ Cr√©er la table de destination
CREATE OR REPLACE TABLE RAW_EVENTS (
  event_id      INTEGER,
  timestamp     TIMESTAMP,
  user_id       VARCHAR(50),
  event_type    VARCHAR(100),
  value         FLOAT,
  source        VARCHAR(50)
);
```

üìñ Docs officielles :
- [CREATE DATABASE](https://docs.snowflake.com/fr/sql-reference/sql/create-database)
- [CREATE SCHEMA](https://docs.snowflake.com/fr/sql-reference/sql/create-schema)
- [CREATE TABLE](https://docs.snowflake.com/fr/sql-reference/sql/create-table)
- [Types de donn√©es](https://docs.snowflake.com/fr/sql-reference-data-types)

### 2.2 Types de donn√©es courants

| Type Snowflake | Exemples | Notes |
|---|---|---|
| `INTEGER` / `NUMBER` | 1, 42, -5 | Entiers |
| `FLOAT` / `DOUBLE` | 3.14, -0.5 | D√©cimaux |
| `VARCHAR(n)` | "hello" | Cha√Æne jusqu'√† n chars |
| `DATE` | 2024-01-15 | Date seule |
| `TIMESTAMP` | 2024-01-15 10:30:00 | Date + heure |
| `BOOLEAN` | TRUE / FALSE | Bool√©en |
| `VARIANT` | `{"key": "val"}` | JSON semi-structur√© |

---

## 3. Les Stages : Zone de Transit

Un **Stage** est une zone de stockage temporaire o√π les fichiers transitent avant d'√™tre charg√©s dans une table.

### 3.1 Types de Stages

```mermaid
mindmap
  root((Stages\nSnowflake))
    Internal
      User Stage
        Syntaxe: @~
        Personnel, test
      Table Stage
        Syntaxe: @%MA_TABLE
        Li√© √† une table
      Named Stage
        Syntaxe: @mon_stage
        Partageable √©quipe
    External
      GCS
        gcs://bucket/
      S3
        s3://bucket/
      Azure Blob
        azure://container/
```

### 3.2 Comparaison des Stages

| Type | Syntaxe | Stockage | Usage recommand√© |
|---|---|---|---|
| User Stage | `@~` | Interne Snowflake | Tests perso rapides |
| Table Stage | `@%NOM_TABLE` | Interne Snowflake | Li√© √† une seule table |
| Named Stage (interne) | `@mon_stage` | Interne Snowflake | Partageable entre √©quipes |
| Named Stage (externe) | `@mon_stage_gcs` | GCS / S3 / Azure | **Production, volumes importants** |

### 3.3 Cr√©er un Stage Interne Nomm√©

```sql
-- Stage interne simple
CREATE OR REPLACE STAGE mon_stage_interne
  COMMENT = 'Stage interne pour chargement CSV';

-- Lister les fichiers dans le stage
LIST @mon_stage_interne;

-- Supprimer un fichier du stage
REMOVE @mon_stage_interne/mon_fichier.csv;
```

üìñ [CREATE STAGE](https://docs.snowflake.com/fr/sql-reference/sql/create-stage)

---

## 4. File Formats : D√©crire vos Fichiers

Un **File Format** est un objet Snowflake qui d√©crit comment interpr√©ter les fichiers (s√©parateur, encoding, header‚Ä¶).

### 4.1 Format CSV

```sql
CREATE OR REPLACE FILE FORMAT csv_file
  TYPE = CSV
  FIELD_DELIMITER = ','          -- S√©parateur de colonnes
  SKIP_HEADER = 1                -- Ignorer la 1√®re ligne (en-t√™tes)
  FIELD_OPTIONALLY_ENCLOSED_BY = '"'  -- Guillemets autour des champs
  NULL_IF = ('NULL', 'null', '', '\\N')  -- Valeurs ‚Üí NULL
  EMPTY_FIELD_AS_NULL = TRUE
  TRIM_SPACE = TRUE              -- Supprimer les espaces
  DATE_FORMAT = 'YYYY-MM-DD'
  TIMESTAMP_FORMAT = 'YYYY-MM-DD HH24:MI:SS';
```

### 4.2 Format JSON

```sql
CREATE OR REPLACE FILE FORMAT fmt_json
  TYPE = JSON
  STRIP_OUTER_ARRAY = TRUE   -- [{...},{...}] ‚Üí lignes s√©par√©es
  STRIP_NULL_VALUES = FALSE
  IGNORE_UTF8_ERRORS = FALSE;
```

### 4.3 Format Parquet

```sql
CREATE OR REPLACE FILE FORMAT fmt_parquet
  TYPE = PARQUET
  SNAPPY_COMPRESSION = TRUE
  BINARY_AS_TEXT = FALSE;
```

üìñ [CREATE FILE FORMAT](https://docs.snowflake.com/fr/sql-reference/sql/create-file-format)

---

## 5. COPY INTO : Chargement en Masse

`COPY INTO` est la commande principale pour charger des fichiers depuis un stage vers une table.

### 5.1 Syntaxe compl√®te

```sql
COPY INTO ma_table
  FROM @mon_stage/fichier.csv
  FILE_FORMAT = (TYPE = 'CSV' FIELD_DELIMITER = ',' SKIP_HEADER = 1)
  ON_ERROR = 'CONTINUE'   -- Comportement en cas d'erreur
  PURGE = FALSE           -- Supprimer le fichier apr√®s chargement
  FORCE = FALSE;          -- Ne pas recharger les fichiers d√©j√† trait√©s
```

### 5.2 Options ON_ERROR

```mermaid
flowchart TD
    A[Erreur d√©tect√©e\ndans le fichier] --> B{ON_ERROR}
    B -->|ABORT_STATEMENT\nd√©faut| C["üõë Stoppe tout\nRollback complet"]
    B -->|CONTINUE| D["‚è© Ignore la ligne\nCharge le reste"]
    B -->|SKIP_FILE| E["üìÅ Ignore tout\nle fichier"]
    B -->|SKIP_FILE_n| F["üìÅ Ignore si\n> n erreurs"]

    style C fill:#C0392B,color:#fff
    style D fill:#27AE60,color:#fff
    style E fill:#E67E22,color:#fff
    style F fill:#F39C12,color:#fff
```

| Option | Comportement | Quand l'utiliser |
|---|---|---|
| `ABORT_STATEMENT` (d√©faut) | Stoppe tout, rollback | Donn√©es critiques, 0 tol√©rance erreur |
| `CONTINUE` | Charge les lignes valides, ignore les mauvaises | Donn√©es semi-fiables |
| `SKIP_FILE` | Ignore tout le fichier si 1 erreur | Fichiers atomiques |
| `SKIP_FILE_n` | Ignore le fichier si > n erreurs | Seuil d'erreur tol√©rable |

### 5.3 Valider avant de charger (Dry Run)

```sql
-- VALIDATION_MODE : teste le fichier sans charger
COPY INTO ma_table FROM @mon_stage/fichier.csv
  FILE_FORMAT = (FORMAT_NAME = 'csv_file')
  VALIDATION_MODE = 'RETURN_ALL_ERRORS';
```

### 5.4 COPY avec Transformation

```sql
-- Charger avec transformation √† la vol√©e
COPY INTO clients (id, nom, email, date_inscription)
FROM (
  SELECT
    $1::INTEGER               AS id,
    UPPER($2)                 AS nom,
    LOWER($3)                 AS email,
    TO_DATE($4, 'DD/MM/YYYY') AS date_inscription
  FROM @mon_stage/clients.csv
)
FILE_FORMAT = (FORMAT_NAME = 'csv_file');
```

### 5.5 V√©rifier l'historique de chargement

```sql
-- Historique des 24 derni√®res heures
SELECT
  FILE_NAME, STATUS, ROW_COUNT, ERROR_COUNT,
  FIRST_ERROR, FIRST_ERROR_LINE, LAST_LOAD_TIME
FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(
  TABLE_NAME => 'RAW_EVENTS',
  START_TIME => DATEADD('HOURS', -24, CURRENT_TIMESTAMP())
))
ORDER BY LAST_LOAD_TIME DESC;
```

üìñ [COPY INTO \<table\>](https://docs.snowflake.com/fr/sql-reference/sql/copy-into-table)

---

## 6. Workflow Complet GCS ‚Üí Snowflake

Cas concret : ingestion du fichier `HealthApp_2k.log` depuis Google Cloud Storage.

### 6.1 Sch√©ma du workflow GCS

```mermaid
sequenceDiagram
    actor Admin as üë§ Admin Snowflake
    participant SF as ‚ùÑÔ∏è Snowflake
    participant IAM as üîê GCS IAM
    participant GCS as ‚òÅÔ∏è GCS Bucket

    Admin->>SF: CREATE STORAGE INTEGRATION gcs_int_ada
    SF-->>Admin: Retourne STORAGE_GCP_SERVICE_ACCOUNT (email)
    Admin->>IAM: Ajouter l'email comme Storage Object Viewer
    IAM-->>Admin: ‚úÖ Permission accord√©e

    Admin->>SF: CREATE STAGE gcs_stage (URL = gcs://ada_snowflake/)
    Admin->>SF: LIST @gcs_stage
    SF->>GCS: V√©rifie l'acc√®s au bucket
    GCS-->>SF: Liste des fichiers
    SF-->>Admin: ‚úÖ Fichiers visibles

    Admin->>SF: COPY INTO RAW_EVENTS FROM @gcs_stage
    SF->>GCS: Lit HealthApp_2k.log
    GCS-->>SF: Contenu du fichier
    SF-->>Admin: ‚úÖ Donn√©es charg√©es
```

### 6.2 √âtape 1 ‚Äî D√©finir le contexte

```sql
USE ROLE ACCOUNTADMIN;
USE DATABASE HEALTH_APP;
USE SCHEMA RAW;
```

> ‚ö†Ô∏è **Pourquoi ACCOUNTADMIN ?** La cr√©ation d'une Storage Integration n√©cessite des privil√®ges √©lev√©s. En production, cr√©ez un r√¥le d√©di√© avec uniquement les permissions n√©cessaires.

### 6.3 √âtape 2 ‚Äî Cr√©er la Storage Integration GCS

```sql
CREATE OR REPLACE STORAGE INTEGRATION gcs_int_ada
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = GCS
  ENABLED = TRUE
  STORAGE_ALLOWED_LOCATIONS = ('gcs://ada_snowflake/');
```

> üí° **C'est quoi une Storage Integration ?** C'est un objet Snowflake qui contient les credentials s√©curis√©s pour acc√©der √† un bucket cloud. Elle √©vite de mettre des cl√©s API en dur dans le code.

### 6.4 √âtape 3 ‚Äî R√©cup√©rer l'email Snowflake

```sql
DESC INTEGRATION gcs_int_ada;
-- ‚Üí Copier la valeur de STORAGE_GCP_SERVICE_ACCOUNT
-- Exemple : abc123@gcpserviceaccount.com
```

**Ensuite dans Google Cloud Console :**
1. Aller dans `GCS > Votre bucket > Permissions`
2. Cliquer `+ Grant Access`
3. Coller l'email Snowflake
4. R√¥le : `Storage Object Viewer` (lecture) ou `Storage Object Admin` (lecture + √©criture)

üìñ [Configurer GCS IAM](https://docs.snowflake.com/fr/user-guide/data-load-gcs-config)

### 6.5 √âtape 4 ‚Äî Cr√©er le File Format

```sql
CREATE OR REPLACE FILE FORMAT csv_file
  TYPE = CSV
  FIELD_DELIMITER = ','
  SKIP_HEADER = 1
  FIELD_OPTIONALLY_ENCLOSED_BY = '"';
```

### 6.6 √âtape 5 ‚Äî Cr√©er le Stage Externe GCS

```sql
CREATE OR REPLACE STAGE gcs_stage
  URL = 'gcs://ada_snowflake/'
  STORAGE_INTEGRATION = gcs_int_ada
  FILE_FORMAT = csv_file;
```

### 6.7 √âtape 6 ‚Äî Tester l'acc√®s

```sql
-- Lister les fichiers visibles dans le bucket
LIST @gcs_stage;
-- Doit retourner les fichiers pr√©sents dans gcs://ada_snowflake/
```

### 6.8 √âtape 7 ‚Äî Charger les donn√©es

```sql
COPY INTO RAW_EVENTS
FROM @gcs_stage
FILES = ('HealthApp_2k.log')   -- Fichier sp√©cifique
ON_ERROR = 'CONTINUE';
```

### 6.9 √âtape 8 ‚Äî V√©rifier les donn√©es

```sql
SELECT * FROM RAW_EVENTS LIMIT 20;

-- V√©rification du volume
SELECT COUNT(*) AS total_lignes FROM RAW_EVENTS;

-- V√©rification de la r√©partition
SELECT event_type, COUNT(*) FROM RAW_EVENTS GROUP BY 1 ORDER BY 2 DESC;
```

### 6.10 R√©sum√© visuel du r√¥le de chaque composant

```mermaid
graph TB
    subgraph S√©curit√©
        A["üîê Storage Integration\ngcs_int_ada\n‚Üí Autorise Snowflake\n√† acc√©der √† GCS"]
    end
    subgraph Localisation
        B["üó∫Ô∏è External Stage\ngcs_stage\n‚Üí Pointe vers\ngcs://ada_snowflake/"]
    end
    subgraph Format
        C["üìÑ File Format\ncsv_file\n‚Üí D√©crit la structure\ndu fichier CSV"]
    end
    subgraph Chargement
        D["üì• COPY INTO\n‚Üí Lit, parse\net ins√®re les donn√©es"]
    end
    subgraph Destination
        E["üóÉÔ∏è Table RAW_EVENTS\n‚Üí Donn√©es disponibles\npour analyse"]
    end

    A --> B --> C --> D --> E
```

üìñ Docs officielles GCS :
- [CREATE STORAGE INTEGRATION](https://docs.snowflake.com/fr/sql-reference/sql/create-storage-integration)
- [Configurer GCS pour Snowflake](https://docs.snowflake.com/fr/user-guide/data-load-gcs-config)

---

## 7. Chargement INSERT (Petits Volumes)

Pour de petits volumes de donn√©es (tests, r√©f√©rentiels statiques), `INSERT` est plus simple.

```sql
-- INSERT simple
INSERT INTO clients (id, nom, email) VALUES
  (1, 'Alice Dupont', 'alice@example.com'),
  (2, 'Bob Martin',  'bob@example.com'),
  (3, 'Clara Petit',  'clara@example.com');

-- INSERT depuis une autre table (ETL interne)
INSERT INTO clients_archive
SELECT * FROM clients WHERE created_at < DATEADD('YEAR', -1, CURRENT_DATE());
```

> ‚ö†Ô∏è **Attention** : `INSERT` cr√©e une transaction par lot de lignes. Pour des millions de lignes, pr√©f√©rez toujours `COPY INTO` qui est massivement parall√©lis√©.

üìñ [INSERT](https://docs.snowflake.com/fr/sql-reference/sql/insert)

---

## 8. Snowpipe : Ingestion Continue

Snowpipe charge automatiquement les nouveaux fichiers d√®s qu'ils arrivent dans un stage.

### 8.1 Comment √ßa fonctionne

```mermaid
sequenceDiagram
    participant App as üñ•Ô∏è Application
    participant GCS as ‚òÅÔ∏è GCS Bucket
    participant Notif as üì¢ GCS Pub/Sub
    participant Pipe as üîß Snowpipe
    participant Table as üóÉÔ∏è Table

    App->>GCS: D√©pose un nouveau fichier
    GCS->>Notif: √âv√©nement "object created"
    Notif->>Pipe: D√©clenche AUTO_INGEST
    Pipe->>GCS: Lit le nouveau fichier
    Pipe->>Table: COPY INTO (micro-batch)
    Table-->>App: Donn√©es disponibles en ~secondes
```

### 8.2 Cr√©er un Pipe

```sql
-- Cr√©er le pipe avec AUTO_INGEST
CREATE OR REPLACE PIPE pipe_events
  AUTO_INGEST = TRUE
AS
COPY INTO events_raw
  FROM @gcs_stage/events/
  FILE_FORMAT = (FORMAT_NAME = 'fmt_json');

-- R√©cup√©rer le Notification Channel (Pub/Sub GCS)
DESC PIPE pipe_events;
-- ‚Üí Copier notification_channel pour configurer GCS Pub/Sub
```

### 8.3 Surveiller Snowpipe

```sql
-- Statut du pipe
SELECT PARSE_JSON(SYSTEM$PIPE_STATUS('pipe_events'));

-- Historique d'ingestion
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(
  TABLE_NAME => 'EVENTS_RAW',
  START_TIME => DATEADD('HOURS', -1, CURRENT_TIMESTAMP())
));

-- Pause / Reprise
ALTER PIPE pipe_events PAUSE;
ALTER PIPE pipe_events RESUME;
```

üìñ Docs officielles :
- [Snowpipe Introduction](https://docs.snowflake.com/fr/user-guide/data-load-snowpipe-intro)
- [Snowpipe Streaming](https://docs.snowflake.com/fr/user-guide/snowpipe-streaming/data-load-snowpipe-streaming-overview)

### 8.4 COPY INTO vs Snowpipe

```mermaid
quadrantChart
    title Choisir entre COPY INTO et Snowpipe
    x-axis Basse frequence ... Haute frequence
    y-axis Petit volume ... Grand volume
    quadrant-1 Snowpipe ideal
    quadrant-2 Snowpipe ou Streaming
    quadrant-3 COPY INTO ou INSERT
    quadrant-4 COPY INTO batch
    COPY INTO batch: [0.2, 0.8]
    Snowpipe: [0.75, 0.6]
    INSERT: [0.1, 0.15]
    Streaming API: [0.9, 0.85]
```

---

## 9. PUT & GET : CLI SnowSQL

`PUT` et `GET` permettent de transf√©rer des fichiers entre votre machine locale et un stage **interne**.

> ‚ö†Ô∏è `PUT` et `GET` fonctionnent **uniquement en SnowSQL CLI** ou via le connecteur Python. Pas dans l'UI Snowsight.

### 9.1 Installer SnowSQL

```bash
# macOS
brew install --cask snowflake-snowsql

# Linux
curl -O https://sfc-repo.snowflakecomputing.com/snowsql/bootstrap/1.2/linux_x86_64/snowsql-1.2.9-linux_x86_64.bash
bash snowsql-1.2.9-linux_x86_64.bash

# Connexion
snowsql -a <account_identifier> -u <username>
```

### 9.2 PUT ‚Äî Uploader un fichier vers un Stage

```sql
-- Uploader un fichier local
PUT file:///chemin/local/data.csv @mon_stage;

-- Uploader plusieurs fichiers (wildcard)
PUT file:///data/*.csv @mon_stage AUTO_COMPRESS=TRUE;

-- Options compl√®tes
PUT file:///data/big_file.csv @mon_stage
  AUTO_COMPRESS = TRUE    -- Compresser avant upload
  PARALLEL = 4            -- Threads parall√®les
  OVERWRITE = FALSE;      -- Ne pas √©craser si d√©j√† pr√©sent
```

### 9.3 GET ‚Äî T√©l√©charger depuis un Stage

```sql
-- T√©l√©charger un fichier
GET @mon_stage/data.csv file:///tmp/output/;

-- T√©l√©charger tous les fichiers
GET @mon_stage file:///tmp/output/ PARALLEL = 8;
```

### 9.4 Via Python Connector

```python
import snowflake.connector

conn = snowflake.connector.connect(
    account='mon_account',
    user='mon_user',
    password='mon_password',
    database='HEALTH_APP',
    schema='RAW'
)

cur = conn.cursor()

# Upload vers stage
cur.execute("PUT file:///tmp/HealthApp_2k.log @mon_stage AUTO_COMPRESS=TRUE")

# Charger dans la table
cur.execute("""
    COPY INTO RAW_EVENTS
    FROM @mon_stage/HealthApp_2k.log.gz
    FILE_FORMAT = (FORMAT_NAME = 'csv_file')
    ON_ERROR = 'CONTINUE'
""")

# V√©rifier
cur.execute("SELECT COUNT(*) FROM RAW_EVENTS")
print(f"Lignes charg√©es : {cur.fetchone()[0]}")

conn.close()
```

---

## 10. Formats de Fichiers Support√©s

```mermaid
mindmap
  root((File Formats\nSnowflake))
    Structur√©s
      CSV
        S√©parateur configurable
        SKIP_HEADER
        NULL_IF
      TSV
        Tab-separated
    Semi-structur√©s
      JSON
        VARIANT
        STRIP_OUTER_ARRAY
      AVRO
        Kafka / Streaming
      XML
        Legacy, ERP
    Columnar
      Parquet
        Snappy compression
        MATCH_BY_COLUMN_NAME
      ORC
        Hadoop / Hive
```

| Format | Compression auto | Semi-structur√© | Perf. lecture | Recommand√© pour |
|---|---|---|---|---|
| CSV | Optionnelle | Non | Moyenne | Exports, fichiers plats |
| JSON | Optionnelle | ‚úÖ Oui | Moyenne | APIs, logs, √©v√©nements |
| Parquet | ‚úÖ Oui (Snappy) | Partiel | ‚ö° Excellente | Analytics, Data Lake |
| ORC | ‚úÖ Oui | Non | ‚ö° Excellente | Ecosyst√®me Hadoop/Hive |
| AVRO | Optionnelle | ‚úÖ Oui | Bonne | Kafka, streaming |
| XML | Non | ‚úÖ Oui | Faible | Legacy, ERP |

---

## 11. üî¥ Dictionnaire des Erreurs Communes

### 11.1 Erreurs Fichiers & Formats

```mermaid
flowchart TD
    A[‚ùå Erreur COPY INTO] --> B{Type d'erreur?}

    B -->|Nombre de colonnes| C["Number of columns\nin file does not match\n‚Üí V√©rifier FIELD_DELIMITER\n‚Üí Inspecter le fichier brut"]
    B -->|Format date| D["Date is not recognized\n‚Üí Sp√©cifier DATE_FORMAT\n‚Üí Utiliser TRY_TO_DATE()"]
    B -->|Valeur nulle| E["Numeric value '' not recognized\n‚Üí Ajouter NULL_IF = ('')\n‚Üí EMPTY_FIELD_AS_NULL = TRUE"]
    B -->|Taille ligne| F["Max row size exceeded\n‚Üí Splitter le fichier\n‚Üí STRIP_OUTER_ARRAY = TRUE"]
    B -->|Compression| G["File is compressed but\nFORMAT specifies no compression\n‚Üí COMPRESSION = 'AUTO'"]

    style A fill:#C0392B,color:#fff
    style C fill:#FDEDEC,color:#000
    style D fill:#FDEDEC,color:#000
    style E fill:#FDEDEC,color:#000
    style F fill:#FDEDEC,color:#000
    style G fill:#FDEDEC,color:#000
```

---

#### Tableau complet des erreurs

| Code / Message | Cause | Solution | Doc |
|---|---|---|---|
| `Number of columns in file does not match` | Nb colonnes fichier ‚â† table | V√©rifier `FIELD_DELIMITER`, inspecter le fichier brut avec `SELECT $1,$2 FROM @stage` | [Troubleshooting](https://docs.snowflake.com/fr/user-guide/data-load-troubleshooting) |
| `Field delimiter ',' found after quoted field` | Guillemets mal ferm√©s dans le CSV | V√©rifier `FIELD_OPTIONALLY_ENCLOSED_BY` et nettoyer les guillemets non √©chapp√©s | [File Format](https://docs.snowflake.com/fr/sql-reference/sql/create-file-format) |
| `Numeric value '' is not recognized` | Champ vide dans colonne num√©rique | Ajouter `NULL_IF = ('')` ou `EMPTY_FIELD_AS_NULL = TRUE` | [File Format](https://docs.snowflake.com/fr/sql-reference/sql/create-file-format) |
| `Date 'xx/xx/xxxx' is not recognized` | Format de date incorrect | Sp√©cifier `DATE_FORMAT = 'DD/MM/YYYY'` ou utiliser `TRY_TO_DATE()` | [TRY_TO_DATE](https://docs.snowflake.com/fr/sql-reference/functions/try_to_date) |
| `Max row size exceeded (16MB)` | Ligne d√©passe 16MB (JSON imbriqu√©) | Splitter le fichier, `STRIP_OUTER_ARRAY=TRUE`, pr√©parer en amont | [Data Prep](https://docs.snowflake.com/fr/user-guide/data-load-considerations-prepare) |
| `File is compressed but FORMAT specifies no compression` | Fichier `.gz` mais `COMPRESSION = NONE` | Changer `COMPRESSION = 'AUTO'` | [File Format](https://docs.snowflake.com/fr/sql-reference/sql/create-file-format) |

### 11.2 Erreurs d'Acc√®s & Stage

| Code / Message | Cause | Solution | Doc |
|---|---|---|---|
| `Stage does not exist or not authorized` | Stage inexistant ou droits manquants | `SHOW STAGES;` et `GRANT USAGE ON STAGE mon_stage TO ROLE mon_role;` | [Access Control](https://docs.snowflake.com/fr/user-guide/security-access-control-privileges) |
| `GCS: 403 Access Denied` | IAM GCS mal configur√© | V√©rifier l'email Snowflake dans les permissions du bucket (`DESC INTEGRATION`) | [GCS Config](https://docs.snowflake.com/fr/user-guide/data-load-gcs-config) |
| `Invalid credentials for GCS bucket` | Storage Integration mal configur√©e | V√©rifier `DESC INTEGRATION` et `ENABLED = TRUE`. Recr√©er si n√©cessaire. | [Storage Integration](https://docs.snowflake.com/fr/sql-reference/sql/create-storage-integration) |
| `File not found in stage` | Chemin ou nom de fichier incorrect | `LIST @mon_stage;` ‚Äî les chemins sont **case-sensitive** | [LIST](https://docs.snowflake.com/fr/sql-reference/sql/list) |

### 11.3 Erreurs de Permissions

| Code / Message | Cause | Solution | Doc |
|---|---|---|---|
| `Insufficient privileges to operate on table` | R√¥le sans droit INSERT | `GRANT INSERT ON TABLE ma_table TO ROLE mon_role;` | [Privileges](https://docs.snowflake.com/fr/user-guide/security-access-control-privileges) |
| `No active warehouse` | Aucun Virtual Warehouse s√©lectionn√© | `USE WAREHOUSE mon_wh;` puis v√©rifier `SHOW WAREHOUSES;` | [Warehouses](https://docs.snowflake.com/fr/user-guide/warehouses-overview) |
| `Schema does not exist` | Sch√©ma absent ou contexte incorrect | `USE DATABASE ma_db; USE SCHEMA mon_schema;` | [USE SCHEMA](https://docs.snowflake.com/fr/sql-reference/sql/use-schema) |

### 11.4 Erreurs Snowpipe

| Code / Message | Cause | Solution | Doc |
|---|---|---|---|
| `Auto-ingest not triggering` | Notification GCS Pub/Sub non configur√©e | V√©rifier `DESC PIPE mon_pipe` et configurer la notification Pub/Sub avec le `notification_channel` | [Snowpipe GCS](https://docs.snowflake.com/fr/user-guide/data-load-snowpipe-auto-gcs) |
| `Files already loaded (skipped)` | Snowpipe ne recharge pas les fichiers trait√©s (normal) | Retraitement : renommer le fichier ou utiliser `COPY INTO` avec `FORCE=TRUE` | [Snowpipe Manage](https://docs.snowflake.com/fr/user-guide/data-load-snowpipe-manage) |
| `Pipe is in PAUSED state` | Pipe mis en pause manuellement ou suite √† erreur | `ALTER PIPE mon_pipe RESUME;` + v√©rifier `SYSTEM$PIPE_STATUS()` | [Snowpipe Manage](https://docs.snowflake.com/fr/user-guide/data-load-snowpipe-manage) |

### 11.5 Commandes de Diagnostic Rapide

```sql
-- ‚ë† Inspecter le fichier brut sans charger
SELECT $1, $2, $3, $4
FROM @gcs_stage/HealthApp_2k.log
(FILE_FORMAT => (TYPE = 'CSV'))
LIMIT 20;

-- ‚ë° Dry run complet (liste toutes les erreurs)
COPY INTO RAW_EVENTS FROM @gcs_stage/HealthApp_2k.log
  FILE_FORMAT = (FORMAT_NAME = 'csv_file')
  VALIDATION_MODE = 'RETURN_ALL_ERRORS';

-- ‚ë¢ Voir l'historique des erreurs de chargement
SELECT
  FILE_NAME, STATUS, ERROR_COUNT,
  FIRST_ERROR, FIRST_ERROR_LINE, FIRST_ERROR_COLUMN_NAME
FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(
  TABLE_NAME => 'RAW_EVENTS',
  START_TIME => DATEADD('HOURS', -24, CURRENT_TIMESTAMP())
))
WHERE STATUS = 'LOAD_FAILED' OR ERROR_COUNT > 0
ORDER BY LAST_LOAD_TIME DESC;

-- ‚ë£ V√©rifier les grants d'un r√¥le
SHOW GRANTS TO ROLE mon_role;

-- ‚ë§ Statut d'un pipe
SELECT PARSE_JSON(SYSTEM$PIPE_STATUS('pipe_events'));

-- ‚ë• Voir les stages disponibles
SHOW STAGES;
```

---

## 12. ‚úÖ Checklist & Bonnes Pratiques

### Avant de charger

- [ ] V√©rifier le format du fichier (s√©parateur, encoding UTF-8, fin de ligne)
- [ ] Tester avec `VALIDATION_MODE = 'RETURN_ALL_ERRORS'` sur un √©chantillon
- [ ] S'assurer que le Virtual Warehouse est actif (`SHOW WAREHOUSES;`)
- [ ] V√©rifier les droits du r√¥le : STAGE, TABLE, WAREHOUSE
- [ ] Estimer le volume : `SMALL` < 10 GB, `MEDIUM` < 100 GB, `LARGE` > 100 GB

### Pendant le chargement

- [ ] Utiliser `ON_ERROR = 'CONTINUE'` en phase de d√©couverte
- [ ] Utiliser `ON_ERROR = 'ABORT_STATEMENT'` en production critique
- [ ] Activer `PURGE = TRUE` uniquement si les fichiers sources ne sont plus utiles
- [ ] Ne **pas** utiliser `FORCE = TRUE` en production (perd la d√©duplication)
- [ ] Partitionner les gros fichiers en chunks de **100-250 MB**

### Apr√®s le chargement

- [ ] Toujours faire un `COUNT(*)` et v√©rifier un √©chantillon
- [ ] Contr√¥ler via `COPY_HISTORY` les √©ventuelles erreurs
- [ ] Archiver ou nettoyer le stage : `REMOVE @stage_name;`
- [ ] Documenter la structure du File Format utilis√©

### Bonnes pratiques g√©n√©rales

- [ ] **Toujours cr√©er un `FILE FORMAT` nomm√©** r√©utilisable (pas inline)
- [ ] **Utiliser des `STORAGE INTEGRATION`** ‚Äî ne jamais mettre de cl√©s en dur
- [ ] **Nommer les objets clairement** : `stage_gcs_health_prod`, `pipe_events_raw`
- [ ] **Monitorer Snowpipe** avec `SYSTEM$PIPE_STATUS` et des alertes Snowflake
- [ ] **Pour les batchs r√©currents** : cr√©er une `TASK` Snowflake plut√¥t qu'un cron externe

---

## üîó Ressources Officielles

| Sujet | Lien |
|---|---|
| Vue d'ensemble chargement | [data-load-overview](https://docs.snowflake.com/fr/user-guide/data-load-overview) |
| CREATE DATABASE | [create-database](https://docs.snowflake.com/fr/sql-reference/sql/create-database) |
| CREATE SCHEMA | [create-schema](https://docs.snowflake.com/fr/sql-reference/sql/create-schema) |
| CREATE TABLE | [create-table](https://docs.snowflake.com/fr/sql-reference/sql/create-table) |
| Types de donn√©es | [sql-reference-data-types](https://docs.snowflake.com/fr/sql-reference-data-types) |
| CREATE STAGE | [create-stage](https://docs.snowflake.com/fr/sql-reference/sql/create-stage) |
| CREATE FILE FORMAT | [create-file-format](https://docs.snowflake.com/fr/sql-reference/sql/create-file-format) |
| COPY INTO \<table\> | [copy-into-table](https://docs.snowflake.com/fr/sql-reference/sql/copy-into-table) |
| INSERT | [insert](https://docs.snowflake.com/fr/sql-reference/sql/insert) |
| CREATE STORAGE INTEGRATION | [create-storage-integration](https://docs.snowflake.com/fr/sql-reference/sql/create-storage-integration) |
| Configurer GCS IAM | [data-load-gcs-config](https://docs.snowflake.com/fr/user-guide/data-load-gcs-config) |
| Snowpipe Introduction | [data-load-snowpipe-intro](https://docs.snowflake.com/fr/user-guide/data-load-snowpipe-intro) |
| Snowpipe Streaming | [snowpipe-streaming-overview](https://docs.snowflake.com/fr/user-guide/snowpipe-streaming/data-load-snowpipe-streaming-overview) |
| Troubleshooting | [data-load-troubleshooting](https://docs.snowflake.com/fr/user-guide/data-load-troubleshooting) |

---

*‚ùÑÔ∏è Snowflake Data Loading ‚Äî Guide Professionnel | docs.snowflake.com/fr*
