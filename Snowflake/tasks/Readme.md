# ‚ùÑÔ∏è Chapitre 5 ‚Äî Les Tasks Snowflake : automatiser et orchestrer ses pipelines

> **Niveau** : D√©butant ‚Üí Interm√©diaire  
> **Dur√©e estim√©e** : 3-4h  
> **Pr√©requis** : Bases SQL, avoir suivi le Chapitre 4 (RBAC), warehouse `COMPUTE_WH` disponible

---

## üìã Sommaire

1. [Introduction aux Tasks](#1-introduction-aux-tasks)
2. [Ex√©cuter les tasks d'un graph](#2-ex√©cuter-les-tasks-dun-graph)
3. [Comportement en cas de bug](#3-comportement-en-cas-de-bug)
4. [Logging & qualit√© de la data](#4-logging--qualit√©-de-la-data)
5. [Gestion des exceptions](#5-gestion-des-exceptions)
6. [Introduction aux Streams](#6-introduction-aux-streams)
7. [Tasks Event Driven](#7-tasks-event-driven)
8. [La task Finalizer](#8-la-task-finalizer)
9. [Architecture du projet health_app](#9-architecture-du-projet-health_app)
10. [Glossaire complet](#10-glossaire-complet)
11. [Checklist de d√©ploiement](#11-checklist-de-d√©ploiement)
12. [Patterns r√©utilisables](#12-patterns-r√©utilisables)
13. [M√©thodologie de r√©solution de probl√®mes](#13-m√©thodologie-de-r√©solution-de-probl√®mes)

---

## 1. Introduction aux Tasks

### Objectifs de cette section
- Savoir cr√©er une task
- D√©finir les options de configuration importantes
- D√©finir l'intervalle d'ex√©cution
- D√©finir le graphe de d√©pendance (DAG)
- Suspendre et re-d√©marrer une task

---

### Qu'est-ce qu'une Task ?

Une **Task** dans Snowflake est un **planificateur SQL**. Elle permet d'ex√©cuter automatiquement du code SQL ou une proc√©dure stock√©e selon deux modes :

```mermaid
graph LR
    T[‚è∞ Task Snowflake]
    T --> M1["üïê Mode planifi√©<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>SCHEDULE = '1 HOURS'<br/>Ex√©cute toutes les heures<br/>quoi qu'il arrive"]
    T --> M2["‚ö° Mode r√©actif<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>WHEN SYSTEM$STREAMHASDATA()<br/>Ex√©cute uniquement<br/>si nouvelles donn√©es"]

    style T fill:#6c5ce7,color:#fff
    style M1 fill:#0984e3,color:#fff
    style M2 fill:#00b894,color:#fff
```

### Cr√©er une Task ‚Äî syntaxe de base

```sql
CREATE OR ALTER TASK mon_schema.ma_task
    WAREHOUSE = COMPUTE_WH      -- moteur de calcul utilis√© (consomme des cr√©dits)
    SCHEDULE  = '1 HOURS'       -- fr√©quence d'ex√©cution automatique
AS
    SELECT 1;                   -- code SQL ex√©cut√© √† chaque d√©clenchement
```

### Options de configuration importantes

| Option | Description | Exemple |
|---|---|---|
| `WAREHOUSE` | Moteur de calcul qui ex√©cute la task | `COMPUTE_WH` |
| `SCHEDULE` | Fr√©quence (root task uniquement) | `'1 HOURS'`, `'5 MINUTES'`, `'USING CRON 0 * * * * UTC'` |
| `AFTER` | D√©pendance vers une autre task | `AFTER mon_schema.ma_root_task` |
| `WHEN` | Condition pour s'ex√©cuter | `WHEN SYSTEM$STREAMHASDATA('mon_stream')` |
| `USER_TASK_TIMEOUT_MS` | Timeout en millisecondes | `3600000` (= 1h) |
| `SUSPEND_TASK_AFTER_NUM_FAILURES` | Suspension auto apr√®s N √©checs | `3` |

### Intervalle d'ex√©cution ‚Äî 2 syntaxes

```sql
-- Syntaxe simple (minutes ou heures)
SCHEDULE = '30 MINUTES'
SCHEDULE = '1 HOURS'

-- Syntaxe CRON (plus flexible ‚Äî format Unix standard)
-- Format : minute heure jour_mois mois jour_semaine timezone
SCHEDULE = 'USING CRON 0 * * * * UTC'    -- toutes les heures pile
SCHEDULE = 'USING CRON 0 8 * * MON UTC'  -- tous les lundis √† 8h UTC
SCHEDULE = 'USING CRON 0 0 1 * * UTC'    -- le 1er de chaque mois √† minuit
```

### D√©finir un graphe de d√©pendance (DAG)

Un **DAG** (Directed Acyclic Graph) est un ensemble de tasks ordonn√©es avec des d√©pendances. La structure est toujours la m√™me : une **root task** qui d√©clenche des **child tasks**.

```mermaid
graph TD
    ROOT["üå± ROOT TASK<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>Schedule = '1 HOURS'<br/>data_quality_task<br/>(d√©clenche tout le DAG)"]

    ROOT --> C1["üì¶ Child Task 1<br/>hih_listener_manager<br/>AFTER root_task"]
    ROOT --> C2["üì¶ Child Task 2<br/>step_lsc<br/>AFTER root_task"]
    ROOT --> C3["üì¶ Child Task 3<br/>step_screenutil<br/>AFTER root_task"]

    C1 --> FIN["üèÅ FINALIZER<br/>finalize_transformation<br/>FINALIZE = root_task<br/>(s'ex√©cute TOUJOURS en dernier)"]
    C2 --> FIN
    C3 --> FIN

    style ROOT fill:#6c5ce7,color:#fff
    style C1 fill:#0984e3,color:#fff
    style C2 fill:#0984e3,color:#fff
    style C3 fill:#0984e3,color:#fff
    style FIN fill:#e17055,color:#fff
```

```sql
-- Root task : a un SCHEDULE, d√©marre tout le graphe
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 HOURS'
AS
    CALL raw.data_quality();

-- Child tasks : ont un AFTER, PAS de SCHEDULE
CREATE OR ALTER TASK raw.hih_listener_manager
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task       -- ‚Üê d√©pendance
AS
    CALL raw.enrich_data('hih_listener_manager', 'HiH_ListenerManager');
```

> üí° **R√®gle fondamentale** : dans un DAG, **seule la root task a un `SCHEDULE`**. Les children n'ont que `AFTER`. Une task ne peut pas avoir les deux.

### Cycle de vie d'une Task

```mermaid
stateDiagram-v2
    [*] --> SUSPENDED : CREATE OR ALTER TASK

    SUSPENDED --> RESUMED : ALTER TASK ... RESUME
    RESUMED --> SUSPENDED : ALTER TASK ... SUSPEND
    RESUMED --> RUNNING : Schedule d√©clench√©\nou EXECUTE TASK
    RUNNING --> SUCCEEDED : Ex√©cution OK
    RUNNING --> FAILED : Erreur SQL
    RUNNING --> SKIPPED : WHEN = FALSE\n(stream vide)
    SUCCEEDED --> RESUMED : En attente\ndu prochain run
    FAILED --> RESUMED : En attente\ndu prochain run
    SKIPPED --> RESUMED : En attente\ndu prochain run
```

### Suspendre et re-d√©marrer ‚Äî ordre obligatoire

```mermaid
sequenceDiagram
    participant Dev as üë®‚Äçüíª D√©veloppeur
    participant SF as ‚ùÑÔ∏è Snowflake

    Dev->>SF: ALTER TASK root_task SUSPEND
    Note over SF: ‚úÖ Modification autoris√©e

    Dev->>SF: CREATE OR ALTER TASK root_task ... (modif)
    Dev->>SF: ALTER TASK child_task_1 RESUME
    Dev->>SF: ALTER TASK child_task_2 RESUME
    Note over Dev: ‚ö†Ô∏è Enfants EN PREMIER
    Dev->>SF: ALTER TASK root_task RESUME
    Note over Dev: üîë Root task EN DERNIER
```

```sql
-- 1. Suspendre (OBLIGATOIRE avant modification)
ALTER TASK raw.data_quality_task SUSPEND;

-- 2. Modifier la task
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '2 HOURS'  -- ‚Üê modification
AS ...;

-- 3. Re-d√©marrer : ENFANTS d'abord, ROOT en dernier
ALTER TASK raw.hih_listener_manager  RESUME;
ALTER TASK raw.step_lsc              RESUME;
ALTER TASK raw.step_screenutil       RESUME;
ALTER TASK raw.data_quality_task     RESUME;  -- ‚Üê EN DERNIER
```

> ‚ö†Ô∏è **R√®gle absolue** : `SUSPEND` avant toute modification, et `RESUME` de la root task **en dernier**. Si tu fais l'inverse, les children ne seront pas d√©clench√©s.

---

## 2. Ex√©cuter les tasks d'un graph

### Objectifs
- Ex√©cuter manuellement un DAG
- D√©bugger des erreurs dans les tasks
- Utiliser `TASK_HISTORY` pour retrouver les ex√©cutions

---

### Ex√©cution manuelle

```sql
-- Force le d√©clenchement imm√©diat sans attendre le planning
-- Snowflake d√©clenche la root task, puis toutes les enfants en cascade
EXECUTE TASK raw.data_quality_task;
```

> üí° Tr√®s utile pour tester un nouveau DAG sans attendre la prochaine √©ch√©ance planifi√©e.

### Consulter l'historique d'ex√©cution

```sql
-- Historique des tasks de la derni√®re heure
SELECT *
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY SCHEDULED_TIME DESC;
```

**Colonnes cl√©s √† surveiller :**

| Colonne | Ce qu'elle indique |
|---|---|
| `NAME` | Nom de la task |
| `STATE` | `SUCCEEDED` / `FAILED` / `RUNNING` / `SKIPPED` |
| `SCHEDULED_TIME` | Quand la task √©tait cens√©e s'ex√©cuter |
| `QUERY_START_TIME` | Quand elle a r√©ellement d√©marr√© |
| `COMPLETED_TIME` | Quand elle a termin√© |
| `ERROR_MESSAGE` | D√©tail de l'erreur si `STATE = FAILED` |
| `GRAPH_RUN_GROUP_ID` | ID unique du run complet du DAG |

### Comprendre les √©tats d'une task

```mermaid
graph LR
    S[STATE dans TASK_HISTORY]
    S --> S1["‚úÖ SUCCEEDED<br/>Ex√©cution OK,<br/>pas d'erreur"]
    S --> S2["‚ùå FAILED<br/>Erreur SQL,<br/>voir ERROR_MESSAGE"]
    S --> S3["‚è≠Ô∏è SKIPPED<br/>Condition WHEN = FALSE<br/>ou d√©pendance en √©chec"]
    S --> S4["üîÑ RUNNING<br/>En cours d'ex√©cution"]
    S --> S5["üö´ SUSPENDED<br/>Task inactive,<br/>pas de runs"]

    style S fill:#2d3436,color:#fff
    style S1 fill:#00b894,color:#fff
    style S2 fill:#e17055,color:#fff
    style S3 fill:#fdcb6e,color:#333
    style S4 fill:#0984e3,color:#fff
    style S5 fill:#636e72,color:#fff
```

### D√©bugger une erreur dans une task

```sql
-- √âtape 1 : trouver les tasks en √©chec
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE state = 'FAILED'
  AND schema_name = 'RAW';

-- √âtape 2 : v√©rifier les logs de la table raw.logging
SELECT *
FROM raw.logging
WHERE error_message IS NOT NULL
ORDER BY created_at DESC;

-- √âtape 3 : lister toutes les tasks et leur statut actuel
SHOW TASKS IN SCHEMA HEALTH_APP.RAW;
```

---

## 3. Comportement en cas de bug

### Objectifs
- Comprendre le comportement par d√©faut en cas d'erreur
- Savoir utiliser `RETRY LAST`
- Comprendre l'int√©r√™t de d√©coupler task et logique

---

### Comportement par d√©faut ‚Äî propagation des erreurs

Quand une task **enfant** √©choue dans un DAG :

```mermaid
graph TD
    ROOT["üå± data_quality_task<br/>‚úÖ OK"]
    ROOT --> C1["hih_listener_manager<br/>‚úÖ OK"]
    ROOT --> C2["step_lsc<br/>‚ùå FAILED"]
    ROOT --> C3["step_screenutil<br/>‚úÖ OK<br/>(continue malgr√© l'√©chec)"]

    C1 --> FIN["finalize_transformation<br/>‚ö†Ô∏è FAILED<br/>(d√©tecte les erreurs)"]
    C2 --> FIN
    C3 --> FIN

    subgraph "Run #2 (prochain cycle)"
        R2["üîÑ Repart depuis<br/>data_quality_task<br/>(tout recommence)"]
    end

    FIN -.->|"run suivant"| R2

    style ROOT fill:#00b894,color:#fff
    style C1 fill:#00b894,color:#fff
    style C2 fill:#e17055,color:#fff
    style C3 fill:#00b894,color:#fff
    style FIN fill:#fdcb6e,color:#333
    style R2 fill:#6c5ce7,color:#fff
```

> **Comportement important** : les tasks enfants **parall√®les** continuent m√™me si l'une d'elles √©choue. Le run suivant repart toujours depuis le d√©but (root task).

### L'option `RETRY LAST`

```mermaid
graph LR
    NORMAL["EXECUTE TASK root_task<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>Relance TOUT depuis le d√©but<br/>(root + tous les children)"]
    RETRY["EXECUTE TASK root_task RETRY LAST<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>Relance UNIQUEMENT<br/>les tasks FAILED du dernier run"]

    style NORMAL fill:#e17055,color:#fff
    style RETRY fill:#00b894,color:#fff
```

```sql
-- Relancer uniquement les tasks FAILED du dernier run
EXECUTE TASK raw.data_quality_task RETRY LAST;
```

**Quand utiliser `RETRY LAST` ?**
- Le probl√®me √©tait temporaire (r√©seau, warehouse suspendu‚Ä¶)
- Les tasks qui ont r√©ussi ne doivent pas √™tre re-ex√©cut√©es (√©viter les doublons)
- Le DAG est long et relancer tout depuis le d√©but est co√ªteux en cr√©dits

### D√©coupler la d√©finition des tasks de la logique

C'est le principe le plus important de ce chapitre.

```mermaid
graph TD
    subgraph "‚ùå Mauvaise pratique"
        T1["Task step_lsc"] --> L1["Logique SQL directement<br/>dans la task<br/>(difficile √† tester,<br/>√† r√©utiliser, √† d√©bugger)"]
    end

    subgraph "‚úÖ Bonne pratique"
        T2["Task step_lsc<br/>(planificateur uniquement)"] --> P2["CALL raw.enrich_data()<br/>(proc√©dure stock√©e)"]
        P2 --> L2["Logique SQL<br/>dans la proc√©dure<br/>(testable avec CALL,<br/>r√©utilisable, maintenable)"]
    end

    style T1 fill:#e17055,color:#fff
    style T2 fill:#00b894,color:#fff
    style P2 fill:#0984e3,color:#fff
```

```sql
-- ‚ùå Mauvaise pratique : logique dans la task
CREATE OR ALTER TASK raw.step_lsc
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task
AS
    -- Toute la logique est ici : difficile √† tester sans d√©clencher la task
    INSERT INTO staging.step_lsc (event_timestamp, process_id, log_trigger, message)
    SELECT re.event_timestamp, re.process_id, ...
    FROM raw.raw_events re
    LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
    WHERE re.process_name = 'Step_LSC'
      AND da.event_id IS NULL;

-- ‚úÖ Bonne pratique : la task est juste un planificateur
CREATE OR ALTER TASK raw.step_lsc
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL raw.enrich_data('step_lsc', 'Step_LSC', :run_id);
END;
```

**Avantages du d√©couplage :**
- On peut tester la proc√©dure avec `CALL` sans d√©clencher toute la task
- La logique est r√©utilisable dans d'autres contextes
- Plus facile √† d√©bugger (on isole le probl√®me)
- Plus facile √† faire √©voluer sans toucher √† la planification

---

## 4. Logging & qualit√© de la data

### Objectifs
- Mettre en place du logging dans les tasks
- D√©finir une proc√©dure pour tester la qualit√© de la data re√ßue

---

### Architecture du logging

```mermaid
graph LR
    PROC["‚öôÔ∏è Proc√©dure<br/>enrich_data()"] -->|"Succ√®s<br/>n_rows = 5842<br/>error = NULL"| LOG[(raw.logging)]
    PROC -->|"√âchec<br/>n_rows = NULL<br/>error = message"| LOG
    
    FIN["üèÅ Finalizer<br/>finalize_transformation()"] -->|"Lecture des<br/>erreurs du run"| LOG
    LOG -->|"Statut global"| STATUS[(raw.transformation\n_pipeline_status)]

    style PROC fill:#0984e3,color:#fff
    style FIN fill:#e17055,color:#fff
    style LOG fill:#fdcb6e,color:#333
    style STATUS fill:#6c5ce7,color:#fff
```

### La table de logging

```sql
CREATE OR ALTER TABLE raw.logging (
    created_at          TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
    graph_run_group_id  STRING,              -- ID unique du run complet du DAG
    table_name          STRING,              -- quelle table a √©t√© enrichie
    n_rows              NUMBER,              -- nb de lignes ins√©r√©es (NULL si erreur)
    error_message       STRING DEFAULT NULL  -- NULL si succ√®s, message si √©chec
);
```

**Comment lire les logs :**

| `n_rows` | `error_message` | Signification |
|---|---|---|
| `5842` | `NULL` | ‚úÖ Succ√®s ‚Äî 5842 lignes ins√©r√©es |
| `NULL` | `"Table not found..."` | ‚ùå √âchec ‚Äî voir le message d'erreur |
| `0` | `NULL` | ‚ö†Ô∏è Aucune donn√©e nouvelle ce run (normal) |

### La proc√©dure de logging

```sql
CREATE OR REPLACE PROCEDURE raw.log_results(
    graph_run_group_id  STRING,
    table_name          STRING,
    n_rows              NUMBER,
    error_message       STRING
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER   -- s'ex√©cute avec les droits de l'appelant (app_role)
AS $$
    INSERT INTO raw.logging (graph_run_group_id, table_name, n_rows, error_message)
    VALUES (:graph_run_group_id, :table_name, :n_rows, :error_message);
$$;
```

### La proc√©dure de data quality

```sql
CREATE OR REPLACE PROCEDURE raw.data_quality(graph_run_group_id STRING)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
BEGIN
    LET nbre_lignes_incorrectes INT := 0;

    -- D√©tecte les anomalies : timestamp invalide OU process_name invalide
    -- et les ins√®re dans la table de quarantaine data_anomalies
    INSERT INTO raw.data_anomalies (event_id, is_correct_timestamp, is_correct_process_name, graph_run_group_id)
    WITH source AS (
        SELECT
            event_id,
            raw.check_correct_timestamp(event_timestamp)   AS is_correct_timestamp,
            raw.check_correct_process_name(process_name)   AS is_correct_process_name
        FROM raw.raw_events
    )
    SELECT *, :graph_run_group_id AS graph_run_group_id
    FROM source
    WHERE is_correct_timestamp = FALSE
       OR is_correct_process_name = FALSE;

    nbre_lignes_incorrectes := SQLROWCOUNT;  -- nb de lignes ins√©r√©es dans data_anomalies
    RETURN :nbre_lignes_incorrectes;
END;
$$;
```

### Le `graph_run_group_id` ‚Äî le concept cl√© du tracking

```mermaid
graph TD
    RUN1["üîµ Run #1 (10h00)<br/>graph_run_group_id = abc-123"]
    RUN1 --> T1A["data_quality_task<br/>ID = abc-123"]
    RUN1 --> T1B["hih_listener_manager<br/>ID = abc-123"]
    RUN1 --> T1C["step_lsc<br/>ID = abc-123"]

    RUN2["üü£ Run #2 (11h00)<br/>graph_run_group_id = xyz-456"]
    RUN2 --> T2A["data_quality_task<br/>ID = xyz-456"]
    RUN2 --> T2B["hih_listener_manager<br/>ID = xyz-456"]
    RUN2 --> T2C["step_lsc<br/>ID = xyz-456"]

    LOG[(raw.logging)]
    T1A -->|"INSERT"| LOG
    T1B -->|"INSERT"| LOG
    T1C -->|"INSERT"| LOG
    T2A -->|"INSERT"| LOG
    T2B -->|"INSERT"| LOG
    T2C -->|"INSERT"| LOG

    style RUN1 fill:#0984e3,color:#fff
    style RUN2 fill:#6c5ce7,color:#fff
    style LOG fill:#fdcb6e,color:#333
```

```sql
-- Retrouver TOUT ce qui s'est pass√© lors d'un run sp√©cifique
SELECT * FROM raw.logging WHERE graph_run_group_id = 'abc-123';

-- R√©cup√©rer l'ID dans une task (variable syst√®me)
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
```

---

## 5. Gestion des exceptions

### Objectifs
- Attraper les exceptions avec `WHEN OTHER THEN`
- D√©finir et lancer des exceptions personnalis√©es
- Utiliser `SQLERRM` pour comprendre la cause d'une erreur

---

### Structure d'un bloc avec exceptions

```mermaid
graph TD
    CODE["Code SQL<br/>(INSERT, CALL, etc.)"]
    CODE -->|"‚úÖ Succ√®s"| SUC["RETURN r√©sultat<br/>log_results(n_rows, NULL)"]
    CODE -->|"‚ùå Exception"| EXC["WHEN OTHER THEN<br/>bloc EXCEPTION"]
    EXC --> CAP["Capturer SQLERRM<br/>(message d'erreur)"]
    CAP --> LOG["log_results(NULL, SQLERRM)<br/>Enregistrer l'erreur"]
    LOG --> RAISE["RAISE mon_exception<br/>Propager vers l'appelant"]
    RAISE --> FAIL["Task marqu√©e FAILED<br/>dans TASK_HISTORY"]

    style CODE fill:#0984e3,color:#fff
    style SUC fill:#00b894,color:#fff
    style EXC fill:#e17055,color:#fff
    style FAIL fill:#e17055,color:#fff
```

```sql
DECLARE
    -- Exception personnalis√©e
    -- Code n√©gatif (-9999) pour √©viter les conflits avec les codes syst√®me Snowflake
    mon_exception EXCEPTION (-9999, 'Description de mon erreur');

BEGIN
    -- Code qui peut potentiellement √©chouer
    INSERT INTO ma_table ...;

EXCEPTION
    -- WHEN OTHER THEN = attrape TOUTES les exceptions non g√©r√©es
    WHEN OTHER THEN
        -- SQLERRM : variable syst√®me contenant le MESSAGE de l'erreur
        -- Ex: "Table 'STAGING.STEP_LSC' does not exist"
        LET message STRING := SQLERRM;

        -- Logger l'erreur
        INSERT INTO raw.logging (error_message) VALUES (:message);

        -- RAISE : re-propage l'exception vers l'appelant
        -- SANS RAISE : l'erreur est aval√©e silencieusement (dangereux !)
        RAISE mon_exception;
END;
```

### Les 3 variables syst√®me √† conna√Ætre

| Variable | Contient | Disponible |
|---|---|---|
| `SQLROWCOUNT` | Nb de lignes affect√©es par le dernier DML | Apr√®s chaque INSERT/UPDATE/DELETE |
| `SQLERRM` | Message texte de la derni√®re erreur | Dans le bloc `EXCEPTION` uniquement |
| `SQLCODE` | Code num√©rique de la derni√®re erreur | Dans le bloc `EXCEPTION` uniquement |

### Exemple complet ‚Äî `enrich_data` avec exceptions

```sql
CREATE OR REPLACE PROCEDURE raw.enrich_data(
    table_name          STRING,   -- nom de la table staging cible (ex: 'step_lsc')
    process_name        STRING,   -- filtre sur raw_events.process_name
    graph_run_group_id  STRING    -- ID du run pour la tra√ßabilit√©
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
DECLARE
    -- IDENTIFIER() permet d'utiliser une variable STRING comme nom de table
    -- √âquivalent dynamique de : INSERT INTO staging.step_lsc ...
    full_table_name  STRING := CONCAT('staging.', :table_name);
    insert_exception EXCEPTION (-9999, 'Exception in data loading into staging tables');

BEGIN
    LET n_rows INT := 0;

    -- Insertion dans la table staging dynamique
    INSERT INTO IDENTIFIER(:full_table_name) (event_timestamp, process_id, log_trigger, message)
    WITH source AS (
        SELECT
            re.event_timestamp,
            re.process_id,
            raw.extract_log_trigger(re.message) AS log_trigger,   -- UDF d'extraction
            raw.extract_log_message(re.message) AS message        -- UDF d'extraction
        FROM raw.raw_events re
        -- Anti-join : exclure les lignes marqu√©es comme anomalies
        LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
        WHERE re.process_name = :process_name
          AND da.event_id IS NULL        -- ‚Üê seulement les lignes SANS anomalie
    )
    SELECT event_timestamp, process_id, log_trigger, message
    FROM source;

    n_rows := SQLROWCOUNT;  -- r√©cup√®re le nb de lignes ins√©r√©es

    -- Log du SUCC√àS : n_rows = nb ins√©r√©, error_message = NULL
    CALL raw.log_results(:graph_run_group_id, :table_name, :n_rows, NULL);
    RETURN :n_rows;

EXCEPTION
    WHEN OTHER THEN
        -- 1. Log l'√âCHEC : n_rows = NULL, error_message = texte de l'erreur
        -- 2. RAISE re-propage ‚Üí Task marqu√©e FAILED dans TASK_HISTORY
        CALL raw.log_results(:graph_run_group_id, :table_name, NULL, :SQLERRM);
        RAISE insert_exception;

END;
$$;
```

---

## 6. Introduction aux Streams

### Objectifs
- Comprendre le concept de Stream (CDC)
- Savoir cr√©er et lire un stream
- Comprendre quand il est consomm√©

---

### Qu'est-ce qu'un Stream ?

Un **Stream** est un objet Snowflake qui **capture les changements** (INSERT, UPDATE, DELETE) survenus sur une table depuis sa derni√®re lecture. C'est du **Change Data Capture (CDC)** natif.

```mermaid
graph LR
    SRC[("üìã Table raw_events<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>event_id=1 (ancienne)<br/>event_id=2 (ancienne)<br/>event_id=3 ‚Üê NOUVELLE<br/>event_id=4 ‚Üê NOUVELLE")]
    STR[("üåä Stream raw_events_stream<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>‚úÖ event_id=3<br/>‚úÖ event_id=4<br/>(seulement les nouvelles lignes)")]
    SRC -->|"capture<br/>les changements"| STR
    STR -->|"consomm√© lors d'un<br/>INSERT/MERGE utilisant<br/>le stream"| CONSUMED["Stream vid√©<br/>(retour √† z√©ro)"]

    style SRC fill:#0984e3,color:#fff
    style STR fill:#00b894,color:#fff
    style CONSUMED fill:#636e72,color:#fff
```

### Cr√©er un Stream

```sql
-- Stream standard (capture INSERT + UPDATE + DELETE)
CREATE OR REPLACE STREAM raw.raw_events_stream
    ON TABLE raw.raw_events;

-- Stream append-only (capture uniquement les INSERT ‚Äî plus l√©ger)
-- Recommand√© quand la table source ne re√ßoit que des nouvelles lignes
CREATE OR REPLACE STREAM raw.raw_events_stream
    ON TABLE raw.raw_events
    APPEND_ONLY = TRUE;
```

### Colonnes sp√©ciales d'un Stream

Quand tu lis un stream, des colonnes suppl√©mentaires sont automatiquement disponibles :

| Colonne | Type | Contient |
|---|---|---|
| `METADATA$ACTION` | STRING | `INSERT` ou `DELETE` |
| `METADATA$ISUPDATE` | BOOLEAN | `TRUE` si c'est la partie UPDATE d'un changement |
| `METADATA$ROW_ID` | STRING | Identifiant unique de la ligne dans le stream |

### Comportement cl√© : consommation du stream

```mermaid
graph LR
    S[("üåä Stream<br/>contient<br/>des donn√©es")]
    S -->|"SELECT * FROM stream<br/>(lecture seule)"| NC["Stream NON consomm√©<br/>toujours les m√™mes donn√©es"]
    S -->|"INSERT INTO table<br/>SELECT * FROM stream<br/>(DML utilisant le stream)"| C["Stream CONSOMM√â<br/>vid√© apr√®s l'op√©ration"]

    style S fill:#00b894,color:#fff
    style NC fill:#fdcb6e,color:#333
    style C fill:#6c5ce7,color:#fff
```

```sql
-- ‚ùå Ne consomme PAS le stream (lecture simple)
SELECT * FROM raw.raw_events_stream;

-- ‚úÖ Consomme le stream (les donn√©es lues disparaissent du stream)
INSERT INTO staging.raw_events_copy
SELECT * FROM raw.raw_events_stream;

-- V√©rifier si un stream a des donn√©es
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream');
-- ‚Üí TRUE  : donn√©es non consomm√©es pr√©sentes
-- ‚Üí FALSE : stream vide
```

---

## 7. Tasks Event Driven

### Objectifs
- Comprendre l'architecture r√©active vs planifi√©e
- Utiliser `SYSTEM$STREAMHASDATA` dans une task
- D√©bugger des tasks event-driven

---

### Architecture planifi√©e vs r√©active

```mermaid
graph TD
    subgraph "üïê Architecture Planifi√©e"
        T1["Task s'ex√©cute<br/>toutes les heures"] --> C1{"Donn√©es<br/>disponibles ?"}
        C1 -->|"Oui"| P1["‚úÖ Traite les donn√©es"]
        C1 -->|"Non"| W1["üí∏ Warehouse d√©marre<br/>quand m√™me<br/>(cr√©dits consomm√©s inutilement)"]
    end

    subgraph "‚ö° Architecture R√©active (Event Driven)"
        T2["Task v√©rifie<br/>toutes les minutes"] --> C2{"SYSTEM$STREAMHASDATA<br/>= TRUE ?"}
        C2 -->|"Oui"| P2["‚úÖ Traite les donn√©es"]
        C2 -->|"Non"| W2["üéâ SKIPPED<br/>(aucun cr√©dit consomm√©)"]
    end
```

> üí° **Avantage cl√©** : en mode event-driven, quand `SYSTEM$STREAMHASDATA` retourne `FALSE`, la task est marqu√©e `SKIPPED` et le warehouse ne d√©marre **pas**. Pas de cr√©dits consomm√©s pour rien.

### Cr√©er une task d√©clench√©e par un stream

```sql
-- Root task avec SCHEDULE + condition WHEN
-- Le SCHEDULE d√©finit la fr√©quence de V√âRIFICATION, pas d'ex√©cution
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 MINUTES'   -- v√©rifie toutes les minutes
    WHEN SYSTEM$STREAMHASDATA('raw.raw_events_stream')  -- s'ex√©cute SEULEMENT si donn√©es
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL raw.data_quality(:run_id);
END;
```

### D√©bugger une task event-driven

```sql
-- V√©rifier les √©tats : SKIPPED = normal (stream vide), FAILED = erreur
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY scheduled_time DESC;
-- STATE = 'SKIPPED'    ‚Üí normal, stream vide √† ce moment-l√†
-- STATE = 'SUCCEEDED'  ‚Üí donn√©es trait√©es ‚úÖ
-- STATE = 'FAILED'     ‚Üí erreur, voir error_message ‚ùå

-- V√©rifier manuellement l'√©tat du stream
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream');
SELECT COUNT(*) FROM raw.raw_events_stream;  -- combien de lignes en attente ?
```

---

## 8. La task Finalizer

### Objectifs
- D√©finir une task de cl√¥ture de DAG
- Comprendre le r√¥le et la syntaxe du Finalizer
- D√©bugger les tasks Finalizer

---

### Qu'est-ce qu'un Finalizer ?

Le **Finalizer** est une task sp√©ciale qui s'ex√©cute **toujours en dernier**, que le DAG ait r√©ussi ou √©chou√©.

```mermaid
graph TD
    ROOT["üå± identify_new_data_task"]
    ROOT --> C1["hih_listener_manager ‚úÖ"]
    ROOT --> C2["step_lsc ‚ùå"]
    ROOT --> C3["step_screenutil ‚úÖ"]
    C1 --> BARRIER{{"Toutes les tasks<br/>du DAG ont termin√©<br/>(succ√®s OU √©chec)"}}
    C2 --> BARRIER
    C3 --> BARRIER
    BARRIER --> FIN["üèÅ finalize_transformation<br/>FINALIZE = identify_new_data_task<br/><br/>S'ex√©cute TOUJOURS<br/>(m√™me si des tasks ont √©chou√©)"]
    FIN --> STATUS[(transformation\n_pipeline_status)]

    style ROOT fill:#6c5ce7,color:#fff
    style C1 fill:#00b894,color:#fff
    style C2 fill:#e17055,color:#fff
    style C3 fill:#00b894,color:#fff
    style FIN fill:#e17055,color:#fff
    style STATUS fill:#fdcb6e,color:#333
```

**Diff√©rence `AFTER` vs `FINALIZE` :**

| | `AFTER` | `FINALIZE` |
|---|---|---|
| S'ex√©cute apr√®s | UNE task sp√©cifique | TOUTES les tasks du DAG |
| Si la parente a √©chou√© | Ne s'ex√©cute PAS | S'ex√©cute QUAND M√äME |
| Nombre par DAG | Illimit√© | Un seul |
| Usage | D√©pendance normale | Cl√¥ture, nettoyage, notification |

### Table de suivi du pipeline

```sql
-- Stocke le statut global de chaque run du DAG
CREATE OR ALTER TABLE raw.transformation_pipeline_status (
    graph_run_group_id  STRING,     -- ID unique du run
    started_at          TIMESTAMP,  -- heure de d√©marrage (root task)
    finished_at         TIMESTAMP,  -- heure de fin (enregistr√©e par le Finalizer)
    status              STRING      -- 'SUCCEEDED' ou 'FAILED'
);
```

### La proc√©dure `finalize_transformation`

```sql
CREATE OR REPLACE PROCEDURE raw.finalize_transformation(
    graph_run_group_id  STRING,    -- ID du run transmis par la task
    started_at          TIMESTAMP  -- timestamp de d√©marrage de la root task
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS
$$
DECLARE
    pipeline_exception EXCEPTION (-20002, 'Exception in the transformation pipeline');
BEGIN
    LET n_errors INT := 0;

    -- √âtape A : Compter les erreurs de ce run dans raw.logging
    -- error_message IS NOT NULL = au moins une task a plant√©
    SELECT COUNT(*) INTO n_errors
    FROM raw.logging
    WHERE graph_run_group_id = :graph_run_group_id
      AND error_message IS NOT NULL;

    -- √âtape B : Enregistrer le statut global du run
    -- IFF(condition, valeur_si_vrai, valeur_si_faux) = ternaire Snowflake
    INSERT INTO raw.transformation_pipeline_status (graph_run_group_id, started_at, finished_at, status)
    SELECT
        :graph_run_group_id  AS graph_run_group_id,
        :started_at          AS started_at,
        CURRENT_TIMESTAMP()  AS finished_at,
        IFF(:n_errors > 0, 'FAILED', 'SUCCEEDED');  -- ‚Üê statut conditionnel

    -- √âtape C : Nettoyage conditionnel
    IF (n_errors = 0) THEN
        -- Tout s'est bien pass√© ‚Üí nettoyage de la table interm√©diaire
        TRUNCATE TABLE raw.data_to_process;
    ELSE
        -- Des erreurs ont eu lieu ‚Üí propage l'exception (Finalizer = FAILED)
        RAISE pipeline_exception;
    END IF;

END;
$$;
```

### La task Finalizer

```sql
CREATE OR ALTER TASK raw.finalize_transformation
    WAREHOUSE = COMPUTE_WH
    FINALIZE  = 'raw.identify_new_data_task'  -- ‚Üê li√© √† la root task du DAG
AS
DECLARE
    -- R√©cup√®re l'ID du run (partag√© par toutes les tasks du DAG)
    graph_run_group_id STRING    := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
    -- Timestamp de d√©marrage pr√©vu de la root task (pour calculer la dur√©e)
    started_at         TIMESTAMP := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP');
BEGIN
    CALL raw.finalize_transformation(:graph_run_group_id, :started_at);
END;
```

### Flux complet du Finalizer

```mermaid
flowchart TD
    START(["üèÅ Toutes les tasks du DAG<br/>ont termin√© (succ√®s ou √©chec)"])
    START --> PROC["raw.finalize_transformation<br/>(proc√©dure)"]
    PROC --> COUNT["SELECT COUNT(*) INTO n_errors<br/>FROM raw.logging<br/>WHERE error_message IS NOT NULL"]
    COUNT --> INSERT["INSERT INTO transformation_pipeline_status<br/>status = IFF(n_errors > 0, 'FAILED', 'SUCCEEDED')"]
    INSERT --> COND{n_errors = 0 ?}
    COND -->|"Oui ‚úÖ"| TRUNC["TRUNCATE raw.data_to_process<br/>(nettoyage)"]
    COND -->|"Non ‚ùå"| RAISE["RAISE pipeline_exception<br/>Finalizer = FAILED"]
    TRUNC --> END1(["‚úÖ Run termin√©<br/>statut = SUCCEEDED"])
    RAISE --> END2(["‚ùå Run termin√©<br/>statut = FAILED<br/>(visible dans TASK_HISTORY)"])

    style START fill:#6c5ce7,color:#fff
    style COND fill:#fdcb6e,color:#333
    style END1 fill:#00b894,color:#fff
    style END2 fill:#e17055,color:#fff
```

### `SYSTEM$TASK_RUNTIME_INFO` ‚Äî param√®tres utiles

| Param√®tre | Type | Contient |
|---|---|---|
| `'CURRENT_TASK_GRAPH_RUN_GROUP_ID'` | STRING | ID unique du run complet du DAG |
| `'CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP'` | TIMESTAMP | Timestamp pr√©vu de d√©marrage de la root task |
| `'CURRENT_TASK_NAME'` | STRING | Nom complet de la task en cours |

---

## 9. Architecture du projet health_app

### Vue d'ensemble du pipeline complet

```mermaid
graph TD
    SRC[("üì• raw.raw_events<br/>donn√©es brutes ing√©r√©es")]

    SRC --> ROOT["üå± data_quality_task<br/>‚è∞ SCHEDULE 1 HOURS<br/>ou WHEN STREAMHASDATA<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>CALL raw.data_quality()"]

    ROOT --> QA[("üö´ raw.data_anomalies<br/>lignes invalides<br/>en quarantaine")]

    ROOT --> T1["hih_listener_manager"]
    ROOT --> T2["hih_hibroadcastutil"]
    ROOT --> T3["step_standstepcounter"]
    ROOT --> T4["step_sputils"]
    ROOT --> T5["step_lsc"]
    ROOT --> T6["hih_hihealthdatainsertstore"]
    ROOT --> T7["hih_datastatmanager"]
    ROOT --> T8["hih_hisyncutil"]
    ROOT --> T9["step_standreportreceiver"]
    ROOT --> T10["step_screenutil"]

    T1 & T2 & T3 & T4 & T5 & T6 & T7 & T8 & T9 & T10 --> LOG[("üìù raw.logging<br/>tra√ßabilit√©")]
    T1 --> S1[("staging.HiH_ListenerManager")]
    T5 --> S5[("staging.Step_LSC")]
    T10 --> S10[("staging.Step_ScreenUtil")]

    T1 & T2 & T3 & T4 & T5 & T6 & T7 & T8 & T9 & T10 --> FIN["üèÅ finalize_transformation<br/>FINALIZE = root_task"]

    FIN --> STATUS[("üìä transformation<br/>_pipeline_status")]

    style SRC fill:#0984e3,color:#fff
    style ROOT fill:#6c5ce7,color:#fff
    style QA fill:#e17055,color:#fff
    style LOG fill:#fdcb6e,color:#333
    style FIN fill:#e17055,color:#fff
    style STATUS fill:#00b894,color:#fff
```

### Les tables du projet

```mermaid
erDiagram
    RAW_EVENTS {
        INT event_id PK
        TIMESTAMP event_timestamp
        STRING process_name
        INT process_id
        STRING message
    }

    DATA_ANOMALIES {
        INT event_id FK
        BOOLEAN is_correct_timestamp
        BOOLEAN is_correct_process_name
        TIMESTAMP created_at
        STRING graph_run_group_id
    }

    LOGGING {
        TIMESTAMP created_at
        STRING graph_run_group_id
        STRING table_name
        NUMBER n_rows
        STRING error_message
    }

    TRANSFORMATION_PIPELINE_STATUS {
        STRING graph_run_group_id PK
        TIMESTAMP started_at
        TIMESTAMP finished_at
        STRING status
    }

    RAW_EVENTS ||--o{ DATA_ANOMALIES : "event_id"
    LOGGING }o--|| TRANSFORMATION_PIPELINE_STATUS : "graph_run_group_id"
```

### Le LEFT JOIN anti-anomalie

Technique pour exclure les lignes invalides sans les supprimer de la table source :

```sql
-- Exclure les lignes marqu√©es comme anomalies
SELECT re.*
FROM raw.raw_events re
LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
WHERE da.event_id IS NULL;  -- ‚Üê garde UNIQUEMENT les lignes SANS entr√©e dans data_anomalies
```

```mermaid
graph LR
    subgraph "raw_events"
        R1["event_id=1"]
        R2["event_id=2 ‚Üê anomalie"]
        R3["event_id=3"]
        R4["event_id=4 ‚Üê anomalie"]
    end

    subgraph "data_anomalies"
        A2["event_id=2"]
        A4["event_id=4"]
    end

    subgraph "R√©sultat (da.event_id IS NULL)"
        OK1["event_id=1 ‚úÖ"]
        OK3["event_id=3 ‚úÖ"]
    end

    R2 -.->|"match"| A2
    R4 -.->|"match"| A4
    R1 -->|"pas de match ‚Üí inclus"| OK1
    R3 -->|"pas de match ‚Üí inclus"| OK3

    style OK1 fill:#00b894,color:#fff
    style OK3 fill:#00b894,color:#fff
    style A2 fill:#e17055,color:#fff
    style A4 fill:#e17055,color:#fff
```

### Les UDFs requises

| UDF | R√¥le | Signature |
|---|---|---|
| `raw.check_correct_timestamp()` | Valide le format/plage du timestamp | `(TIMESTAMP) ‚Üí BOOLEAN` |
| `raw.check_correct_process_name()` | Valide que le process_name est connu | `(STRING) ‚Üí BOOLEAN` |
| `raw.extract_log_trigger()` | Extrait le type d'√©v√©nement du message brut | `(STRING) ‚Üí STRING` |
| `raw.extract_log_message()` | Nettoie et extrait le message r√©el | `(STRING) ‚Üí STRING` |

---

## 10. Glossaire complet

| Terme | D√©finition |
|---|---|
| **Task** | T√¢che SQL automatis√©e dans Snowflake (planificateur) |
| **DAG** | Directed Acyclic Graph ‚Äî graphe de t√¢ches ordonn√©es sans cycle |
| **Root Task** | T√¢che principale du DAG (a un `SCHEDULE`, d√©marre tout) |
| **Child Task** | T√¢che enfant d√©clench√©e apr√®s une autre (a un `AFTER`) |
| **Finalizer Task** | T√¢che sp√©ciale qui s'ex√©cute apr√®s TOUTES les tasks du DAG |
| **Warehouse** | Moteur de calcul Snowflake (CPU/RAM), consomme des cr√©dits |
| `SCHEDULE` | Fr√©quence de d√©clenchement automatique |
| `AFTER` | D√©pendance ‚Äî s'ex√©cute apr√®s la task cit√©e |
| `FINALIZE` | Param√®tre d√©signant une task comme finaliseur du DAG |
| `WHEN` | Condition suppl√©mentaire pour s'ex√©cuter (ex: STREAMHASDATA) |
| `SUSPEND / RESUME` | D√©sactiver / activer une task |
| `RETRY LAST` | Relancer uniquement les tasks FAILED du dernier run |
| **Stream** | Objet qui capture les changements (CDC) sur une table |
| **Append-Only Stream** | Stream qui capture uniquement les INSERT (plus l√©ger) |
| `SYSTEM$STREAMHASDATA` | Retourne TRUE si un stream a des donn√©es non consomm√©es |
| `SYSTEM$TASK_RUNTIME_INFO` | Expose les infos du run en cours (ID, timestamp...) |
| **graph_run_group_id** | ID unique d'un run complet du DAG ‚Äî partag√© par toutes les tasks |
| **Proc√©dure stock√©e** | Bloc de code SQL nomm√© et r√©utilisable (appel√© avec `CALL`) |
| **UDF** | User Defined Function ‚Äî fonction personnalis√©e |
| `IDENTIFIER()` | Permet d'utiliser une variable STRING comme nom de table dynamique |
| `SQLROWCOUNT` | Nb de lignes affect√©es par le dernier INSERT/UPDATE/DELETE |
| `SQLERRM` | Message texte de la derni√®re erreur (disponible dans `EXCEPTION`) |
| `SQLCODE` | Code num√©rique de la derni√®re erreur |
| `WHEN OTHER THEN` | Intercepte toutes les exceptions non g√©r√©es |
| `RAISE` | Re-propage une exception vers l'appelant |
| `EXECUTE AS CALLER` | La proc√©dure s'ex√©cute avec les droits de l'appelant |
| **CDC** | Change Data Capture ‚Äî m√©canisme de capture des changements |

---

## 11. Checklist de d√©ploiement

### Pr√©requis

```
[ ] Les UDFs existent dans le sch√©ma raw :
    [ ] raw.check_correct_timestamp()
    [ ] raw.check_correct_process_name()
    [ ] raw.extract_log_trigger()
    [ ] raw.extract_log_message()

[ ] Les tables staging existent pour chaque process

[ ] Le warehouse COMPUTE_WH existe et est actif

[ ] Le r√¥le a les droits (voir Chapitre 4 ‚Äî RBAC) :
    [ ] CREATE TASK sur le sch√©ma raw
    [ ] INSERT sur les tables staging
    [ ] EXECUTE sur les proc√©dures
    [ ] CREATE STREAM (si architecture event-driven)
```

### Ordre d'ex√©cution du script

```mermaid
graph TD
    S1["1. USE ROLE / DATABASE / SCHEMA"]
    S2["2. CREATE TABLE raw.data_anomalies"]
    S3["3. CREATE TABLE raw.logging"]
    S4["4. CREATE TABLE raw.transformation_pipeline_status"]
    S5["5. CREATE PROCEDURE raw.log_results()"]
    S6["6. CREATE PROCEDURE raw.data_quality()"]
    S7["7. CREATE PROCEDURE raw.enrich_data()"]
    S8["8. CREATE PROCEDURE raw.finalize_transformation()"]
    S9["9. (optionnel) CREATE STREAM raw.raw_events_stream"]
    S10["10. CREATE TASK raw.data_quality_task (root)"]
    S11["11. CREATE TASK raw.[toutes les tasks enfants]"]
    S12["12. CREATE TASK raw.finalize_transformation (finalizer)"]
    S13["13. ALTER TASK [toutes les enfants] RESUME"]
    S14["14. ALTER TASK raw.finalize_transformation RESUME"]
    S15["15. ALTER TASK raw.data_quality_task RESUME ‚Üê EN DERNIER"]
    S16["16. EXECUTE TASK raw.data_quality_task ‚Üê test manuel"]
    S17["17. V√©rifier TASK_HISTORY + raw.logging"]

    S1 --> S2 --> S3 --> S4 --> S5 --> S6 --> S7 --> S8 --> S9 --> S10 --> S11 --> S12 --> S13 --> S14 --> S15 --> S16 --> S17

    style S15 fill:#e17055,color:#fff
    style S16 fill:#6c5ce7,color:#fff
    style S17 fill:#00b894,color:#fff
```

---

## 12. Patterns r√©utilisables

### Pattern 1 ‚Äî DAG complet avec logging et exceptions

```sql
-- ============================================================
-- ROOT TASK
-- ============================================================
CREATE OR ALTER TASK mon_schema.root_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = '1 HOURS'
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.ma_procedure_principale(:run_id);
END;

-- ============================================================
-- CHILD TASK (dupliquer ce pattern pour chaque enfant)
-- ============================================================
CREATE OR ALTER TASK mon_schema.child_task
    WAREHOUSE = COMPUTE_WH
    AFTER mon_schema.root_task
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.ma_procedure_secondaire(:run_id);
END;

-- ============================================================
-- FINALIZER
-- ============================================================
CREATE OR ALTER TASK mon_schema.finalizer_task
    WAREHOUSE = COMPUTE_WH
    FINALIZE = 'mon_schema.root_task'
AS
DECLARE
    run_id     STRING    := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
    started_at TIMESTAMP := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP');
BEGIN
    CALL mon_schema.ma_procedure_finale(:run_id, :started_at);
END;

-- ============================================================
-- ACTIVATION ‚Äî ordre obligatoire
-- ============================================================
ALTER TASK mon_schema.child_task     RESUME;
ALTER TASK mon_schema.finalizer_task RESUME;
ALTER TASK mon_schema.root_task      RESUME;  -- ‚Üê EN DERNIER
```

### Pattern 2 ‚Äî Task event-driven avec Stream

```sql
-- Cr√©er le stream (append-only si table source = insert only)
CREATE OR REPLACE STREAM mon_schema.ma_table_stream
    ON TABLE mon_schema.ma_table
    APPEND_ONLY = TRUE;

-- Task d√©clench√©e uniquement si le stream a des donn√©es
CREATE OR ALTER TASK mon_schema.ma_task_reactive
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = '1 MINUTES'  -- fr√©quence de v√©rification
    WHEN SYSTEM$STREAMHASDATA('mon_schema.ma_table_stream')  -- condition de d√©clenchement
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.traiter_nouvelles_donnees(:run_id);
END;
```

### Pattern 3 ‚Äî Proc√©dure avec logging et gestion d'erreur

```sql
CREATE OR REPLACE PROCEDURE mon_schema.traiter_table(
    table_name STRING,
    run_id     STRING
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
DECLARE
    full_table  STRING    := CONCAT('mon_staging.', :table_name);
    mon_erreur  EXCEPTION (-9999, 'Erreur lors du traitement');
BEGIN
    LET n INT := 0;

    -- Traitement
    INSERT INTO IDENTIFIER(:full_table) (col1, col2)
    SELECT col1, col2
    FROM mon_schema.ma_source
    WHERE condition = :table_name;

    n := SQLROWCOUNT;  -- nb de lignes ins√©r√©es

    -- Log succ√®s
    CALL mon_schema.log_results(:run_id, :table_name, :n, NULL);
    RETURN :n;

EXCEPTION
    WHEN OTHER THEN
        -- Log √©chec + re-propagation de l'erreur
        CALL mon_schema.log_results(:run_id, :table_name, NULL, :SQLERRM);
        RAISE mon_erreur;

END;
$$;
```

### Pattern 4 ‚Äî Requ√™tes de monitoring standard

```sql
-- ============================================================
-- DASHBOARD D'UN RUN SP√âCIFIQUE
-- ============================================================
SELECT
    table_name,
    n_rows,
    CASE WHEN error_message IS NULL THEN '‚úÖ Succ√®s' ELSE '‚ùå √âchec' END AS statut,
    error_message
FROM raw.logging
WHERE graph_run_group_id = 'TON_RUN_ID'
ORDER BY created_at;

-- ============================================================
-- TASKS EN √âCHEC DES DERNI√àRES 24H
-- ============================================================
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -24, current_timestamp())
))
WHERE state = 'FAILED'
  AND schema_name = 'RAW'
ORDER BY scheduled_time DESC;

-- ============================================================
-- R√âSUM√â PAR RUN (nb succ√®s, nb √©checs)
-- ============================================================
SELECT
    graph_run_group_id,
    MIN(created_at) AS started_at,
    COUNT(*) AS total_tables,
    SUM(CASE WHEN error_message IS NULL THEN 1 ELSE 0 END) AS succes,
    SUM(CASE WHEN error_message IS NOT NULL THEN 1 ELSE 0 END) AS echecs
FROM raw.logging
GROUP BY graph_run_group_id
ORDER BY MIN(created_at) DESC;
```

---

## 13. M√©thodologie de r√©solution de probl√®mes

> Une task ne s'ex√©cute pas comme pr√©vu ? Suis ce guide avant de modifier quoi que ce soit.

### Arbre de d√©cision : "Ma task ne fonctionne pas"

```mermaid
flowchart TD
    START(["‚ùå Probl√®me avec une task"]) --> Q1{Quel sympt√¥me ?}

    Q1 -->|"Task jamais d√©clench√©e"| B1[Chemin A : pas de d√©clenchement]
    Q1 -->|"Task FAILED"| B2[Chemin B : √©chec d'ex√©cution]
    Q1 -->|"Task SKIPPED en permanence"| B3[Chemin C : toujours skipp√©e]
    Q1 -->|"Task SUCCEEDED mais donn√©es manquantes"| B4[Chemin D : r√©sultat incorrect]
    Q1 -->|"Impossible de modifier la task"| B5[Chemin E : modification bloqu√©e]

    B1 --> C1{"SHOW TASKS : task<br/>√† l'√©tat RESUMED ?"}
    C1 -->|"Non (SUSPENDED)"| F1["ALTER TASK ... RESUME;<br/>‚ö†Ô∏è R√©sumer les children D'ABORD<br/>puis la root EN DERNIER"]
    C1 -->|"Oui"| C2{"Root task a<br/>un SCHEDULE ?"}
    C2 -->|"Non"| F2["Ajouter SCHEDULE √† la root task<br/>(children ont AFTER, pas SCHEDULE)"]
    C2 -->|"Oui"| C3{"Droits EXECUTE TASK<br/>sur le compte ?"}
    C3 -->|"Non"| F3["GRANT EXECUTE TASK ON ACCOUNT<br/>TO ROLE <role>"]
    C3 -->|"Oui"| F4["Attendre le prochain<br/>cr√©neau planifi√©<br/>ou EXECUTE TASK ... manuellement"]

    B2 --> C4{"TASK_HISTORY :<br/>ERROR_MESSAGE ?"}
    C4 -->|"Oui"| C5{"Type d'erreur ?"}
    C5 -->|"SQL error<br/>(table, colonne...)"| F5["Tester la proc√©dure<br/>directement avec CALL<br/>pour isoler l'erreur"]
    C5 -->|"Insufficient privileges"| F6["V√©rifier le r√¥le de la task<br/>et ses droits (voir Chap. 4 RBAC)"]
    C5 -->|"Warehouse error"| F7["V√©rifier que le warehouse<br/>existe et n'est pas suspendu<br/>SHOW WAREHOUSES"]
    C4 -->|"Non"| F8["V√©rifier raw.logging<br/>pour les erreurs custom<br/>de la proc√©dure"]

    B3 --> C6{"Task a une<br/>condition WHEN ?"}
    C6 -->|"Oui"| C7{"SYSTEM$STREAMHASDATA<br/>retourne TRUE ?"}
    C7 -->|"Non"| F9["Stream vide = comportement normal<br/>Ins√©rer des donn√©es dans la table source<br/>pour alimenter le stream"]
    C7 -->|"Oui"| F10["V√©rifier le nom du stream<br/>dans la condition WHEN<br/>(typo fr√©quente)"]
    C6 -->|"Non"| F11["Task SKIPPED sans WHEN<br/>= impossible en mode RESUMED<br/>V√©rifier TASK_HISTORY"]

    B4 --> C8{"V√©rifier raw.logging :<br/>n_rows = 0 ou NULL ?"}
    C8 -->|"n_rows = 0"| F12["Source vide pour ce filtre<br/>V√©rifier la condition WHERE<br/>dans la proc√©dure"]
    C8 -->|"n_rows > 0"| F13["Donn√©es ins√©r√©es mais<br/>table cible incorrecte ?<br/>V√©rifier IDENTIFIER(:full_table)"]
    C8 -->|"n_rows = NULL"| F14["Erreur silencieuse :<br/>RAISE absent dans EXCEPTION<br/>V√©rifier la proc√©dure"]

    B5 --> C9{"Task est<br/>√† l'√©tat RESUMED ?"}
    C9 -->|"Oui"| F15["ALTER TASK ... SUSPEND;<br/>avant toute modification"]
    C9 -->|"Non"| F16["V√©rifier les droits :<br/>CREATE TASK ON SCHEMA<br/>ou √™tre propri√©taire de la task"]

    style START fill:#e17055,color:#fff
    style F1 fill:#55efc4,color:#333
    style F2 fill:#55efc4,color:#333
    style F3 fill:#55efc4,color:#333
    style F4 fill:#74b9ff,color:#333
    style F5 fill:#55efc4,color:#333
    style F6 fill:#55efc4,color:#333
    style F7 fill:#55efc4,color:#333
    style F8 fill:#74b9ff,color:#333
    style F9 fill:#fdcb6e,color:#333
    style F10 fill:#55efc4,color:#333
    style F11 fill:#74b9ff,color:#333
    style F12 fill:#55efc4,color:#333
    style F13 fill:#55efc4,color:#333
    style F14 fill:#55efc4,color:#333
    style F15 fill:#55efc4,color:#333
    style F16 fill:#55efc4,color:#333
```

---

### Les 5 √©tapes du diagnostic task

```mermaid
graph LR
    E1["**1. V√©rifier l'√©tat de la task**<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>SHOW TASKS IN SCHEMA raw;<br/>‚Üí colonne 'state' (suspended/started)"]
    E2["**2. Consulter TASK_HISTORY**<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>SELECT * FROM TABLE(<br/>INFORMATION_SCHEMA.TASK_HISTORY(...))<br/>WHERE schema_name = 'RAW';"]
    E3["**3. Lire les logs custom**<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>SELECT * FROM raw.logging<br/>WHERE error_message IS NOT NULL<br/>ORDER BY created_at DESC;"]
    E4["**4. Tester la proc√©dure seule**<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>CALL raw.enrich_data(<br/>'step_lsc', 'Step_LSC', 'test-run-id');"]
    E5["**5. V√©rifier le stream**<br/>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ<br/>SELECT SYSTEM$STREAMHASDATA(<br/>'raw.raw_events_stream');<br/>SELECT COUNT(*) FROM raw.raw_events_stream;"]

    E1 --> E2 --> E3 --> E4 --> E5

    style E1 fill:#6c5ce7,color:#fff
    style E2 fill:#0984e3,color:#fff
    style E3 fill:#00b894,color:#fff
    style E4 fill:#fdcb6e,color:#333
    style E5 fill:#e17055,color:#fff
```

---

### Tableau des erreurs fr√©quentes et leurs causes

| Sympt√¥me | Cause probable | Solution |
|---|---|---|
| Task reste √† `SUSPENDED` pour toujours | `ALTER TASK ... RESUME` non ex√©cut√© | `ALTER TASK <t> RESUME;` (children avant root) |
| `FAILED` : `Insufficient privileges` | R√¥le de la task sans droits | V√©rifier RBAC (Chap. 4) ‚Äî `GRANT EXECUTE TASK`, `INSERT`, etc. |
| `FAILED` : `Object does not exist` | Table staging non cr√©√©e | Cr√©er la table staging avant d'activer les tasks |
| `FAILED` : `Warehouse not found` | Warehouse inexistant ou nom incorrect | `SHOW WAREHOUSES;` et corriger le nom |
| Task toujours `SKIPPED` | Stream toujours vide / WHEN toujours FALSE | Ins√©rer des donn√©es test dans la table source |
| `n_rows = NULL` dans logging | Exception non propag√©e (RAISE manquant) | Ajouter `RAISE` dans le bloc `EXCEPTION` |
| Modification de task bloqu√©e | Task √† l'√©tat `RESUMED` | `ALTER TASK ... SUSPEND;` avant modification |
| Children ne se d√©clenchent pas apr√®s root | Children r√©sum√©s apr√®s la root | Suspendre tout, r√©sumer children d'abord, root en dernier |
| Doublons dans staging apr√®s relance | `RETRY LAST` non utilis√© | Utiliser `EXECUTE TASK ... RETRY LAST;` |
| Finalizer ne s'ex√©cute pas | Task non li√©e avec `FINALIZE =` | V√©rifier la syntaxe `FINALIZE = 'schema.root_task'` |

---

### Commandes de diagnostic rapide (copier-coller)

```sql
-- ============================================================
-- DIAGNOSTIC RAPIDE ‚Äî √† ex√©cuter dans l'ordre
-- ============================================================

-- 1. √âtat de toutes les tasks du sch√©ma
SHOW TASKS IN SCHEMA HEALTH_APP.RAW;

-- 2. Historique des 2 derni√®res heures
SELECT name, state, error_message, scheduled_time, completed_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -2, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY scheduled_time DESC;

-- 3. Tasks en √©chec uniquement
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -24, current_timestamp())
))
WHERE state = 'FAILED' AND schema_name = 'RAW'
ORDER BY scheduled_time DESC;

-- 4. Derniers logs d'erreur custom
SELECT * FROM raw.logging
WHERE error_message IS NOT NULL
ORDER BY created_at DESC
LIMIT 20;

-- 5. Statut des derniers runs du pipeline
SELECT * FROM raw.transformation_pipeline_status
ORDER BY finished_at DESC
LIMIT 10;

-- 6. √âtat du stream
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream') AS has_data;
SELECT COUNT(*) AS pending_rows FROM raw.raw_events_stream;

-- 7. R√¥le actif et ses droits
SELECT CURRENT_ROLE();
SHOW GRANTS TO ROLE app_role;
```

---

## üìö Ressources compl√©mentaires

- [Documentation Snowflake : CREATE TASK](https://docs.snowflake.com/en/sql-reference/sql/create-task)
- [Documentation Snowflake : EXECUTE TASK](https://docs.snowflake.com/en/sql-reference/sql/execute-task)
- [Documentation Snowflake : TASK_HISTORY](https://docs.snowflake.com/en/sql-reference/functions/task_history)
- [Documentation Snowflake : CREATE STREAM](https://docs.snowflake.com/en/sql-reference/sql/create-stream)
- [Documentation Snowflake : SYSTEM$STREAMHASDATA](https://docs.snowflake.com/en/sql-reference/functions/system_streamhasdata)
- [Documentation Snowflake : Gestion des exceptions SQL](https://docs.snowflake.com/en/developer-guide/snowflake-scripting/exception)
- [Documentation Snowflake : SYSTEM$TASK_RUNTIME_INFO](https://docs.snowflake.com/en/sql-reference/functions/system_task_runtime_info)

---

## üéØ Les 5 principes √† retenir

```mermaid
mindmap
  root((Tasks Snowflake))
    D√©couplage
      Task = planificateur uniquement
      Logique dans la proc√©dure
      Testable avec CALL ind√©pendamment
    DAG
      Root task avec SCHEDULE
      Children avec AFTER
      Finalizer avec FINALIZE
      RESUME children avant root
    Logging
      graph_run_group_id relie tout le run
      n_rows + error_message par table
      Finalizer consolide le statut global
    Exceptions
      WHEN OTHER THEN attrape tout
      SQLERRM capture le message
      RAISE propage vers TASK_HISTORY
    Event Driven
      Stream = CDC natif
      WHEN STREAMHASDATA
      SKIPPED = aucun cr√©dit consomm√©
```

---

*Chapitre 5 ‚Äî Cours Snowflake Tasks ¬∑ Projet `health_app` ¬∑ Derni√®re mise √† jour : 2026*
