# ‚ùÑÔ∏è Snowflake ‚Äî Cours complet sur les Tasks
> **Guide d√©butant ¬∑ Projet `health_app`** ¬∑ Optimis√© Notion ¬∑ R√©utilisable sur d'autres projets
---

## üìã Table des mati√®res

1. [Introduction aux Tasks](#1--introduction-aux-tasks)
2. [Ex√©cuter les tasks d'un graph](#2--ex√©cuter-les-tasks-dun-graph)
3. [Comportement des tasks en cas de bug](#3--comportement-des-tasks-en-cas-de-bug)
4. [Logging & qualit√© de la data](#4--logging--qualit√©-de-la-data)
5. [Gestion des exceptions](#5--gestion-des-exceptions)
6. [Introduction aux Streams](#6--introduction-aux-streams)
7. [Cr√©er des tasks "Event Driven"](#7--cr√©er-des-tasks-event-driven)
8. [La task Finalizer](#8--la-task-finalizer)
9. [Architecture du projet health_app](#9--architecture-du-projet-health_app)
10. [Glossaire complet](#10--glossaire-complet)
11. [Checklist de d√©ploiement](#11--checklist-de-d√©ploiement)
12. [Patterns r√©utilisables](#12--patterns-r√©utilisables)

---

## 1 ¬∑ Introduction aux Tasks

### Objectifs de cette section
- Savoir cr√©er une task
- D√©finir les options de configuration les plus importantes
- D√©finir l'intervalle d'ex√©cution
- D√©finir le graphe de d√©pendance
- Suspendre et re-d√©marrer une task

---

### Qu'est-ce qu'une Task ?

Une **Task** dans Snowflake est une t√¢che SQL automatis√©e. Elle permet d'ex√©cuter du code SQL (requ√™tes, proc√©dures stock√©es‚Ä¶) automatiquement selon :
- un **planning** (ex : toutes les heures)
- ou un **d√©clencheur** (ex : quand une autre t√¢che se termine, ou quand un stream a des donn√©es)

### Cr√©er une Task ‚Äî syntaxe de base

```sql
CREATE OR ALTER TASK mon_schema.ma_task
    WAREHOUSE = COMPUTE_WH      -- moteur de calcul utilis√© (consomme des cr√©dits)
    SCHEDULE  = '1 HOURS'       -- fr√©quence d'ex√©cution automatique
AS
    SELECT 1;                   -- code SQL ex√©cut√© √† chaque d√©clenchement
```

### Options de configuration importantes

| Option | Description | Exemple |
|---|---|---|
| `WAREHOUSE` | Entrep√¥t de calcul qui ex√©cute la task | `COMPUTE_WH` |
| `SCHEDULE` | Fr√©quence (root task uniquement) | `'1 HOURS'`, `'5 MINUTES'`, `'USING CRON 0 * * * * UTC'` |
| `AFTER` | D√©pendance vers une autre task | `AFTER mon_schema.ma_root_task` |
| `WHEN` | Condition suppl√©mentaire pour s'ex√©cuter | `WHEN SYSTEM$STREAMHASDATA('mon_stream')` |
| `USER_TASK_TIMEOUT_MS` | Timeout en millisecondes | `3600000` (= 1h) |
| `SUSPEND_TASK_AFTER_NUM_FAILURES` | Suspension auto apr√®s N √©checs | `3` |

### Intervalle d'ex√©cution ‚Äî 2 syntaxes

```sql
-- Syntaxe simple (minutes ou heures)
SCHEDULE = '30 MINUTES'
SCHEDULE = '1 HOURS'

-- Syntaxe CRON (plus flexible ‚Äî format Unix standard)
-- CRON : minute heure jour_mois mois jour_semaine timezone
SCHEDULE = 'USING CRON 0 * * * * UTC'    -- toutes les heures pile
SCHEDULE = 'USING CRON 0 8 * * MON UTC'  -- tous les lundis √† 8h UTC
SCHEDULE = 'USING CRON 0 0 1 * * UTC'    -- le 1er de chaque mois √† minuit
```

### D√©finir un graphe de d√©pendance (DAG)

```sql
-- Root task : a un SCHEDULE, d√©marre tout le graphe
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 HOURS'
AS
    CALL raw.data_quality();

-- Child tasks : ont un AFTER, pas de SCHEDULE
CREATE OR ALTER TASK raw.hih_listener_manager
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task       -- ‚Üê d√©pendance
AS
    CALL raw.enrich_data('hih_listener_manager', 'HiH_ListenerManager');
```

> üí° **R√®gle** : dans un DAG, **seule la root task** a un `SCHEDULE`. Les enfants ont uniquement `AFTER`. Une task ne peut pas avoir les deux.

### Cycle de vie d'une Task

```
[Cr√©ation]
    ‚îÇ
    ‚ñº
SUSPENDED ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                         ‚îÇ
    ‚îÇ  ALTER TASK ... RESUME                  ‚îÇ  ALTER TASK ... SUSPEND
    ‚ñº                                         ‚îÇ
RESUMED ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îÇ  (selon SCHEDULE ou AFTER)
    ‚ñº
RUNNING ‚Üí SUCCEEDED / FAILED
```

### Suspendre et re-d√©marrer

```sql
-- Suspendre (n√©cessaire avant toute modification !)
ALTER TASK raw.data_quality_task SUSPEND;

-- Modifier la task
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '2 HOURS'   -- ‚Üê modification
AS ...;

-- Re-d√©marrer (enfants EN PREMIER, racine EN DERNIER)
ALTER TASK raw.hih_listener_manager  RESUME;
ALTER TASK raw.step_lsc              RESUME;
-- ... tous les enfants ...
ALTER TASK raw.data_quality_task     RESUME;  -- ‚Üê EN DERNIER
```

> ‚ö†Ô∏è **R√®gle absolue** : toujours `SUSPEND` avant de modifier une task. Si tu modifies une task active, Snowflake retourne une erreur.

---

## 2 ¬∑ Ex√©cuter les tasks d'un graph

### Objectifs de cette section
- Savoir ex√©cuter des tasks
- Savoir d√©bugger des erreurs dans les tasks
- Utiliser le task history pour retrouver les ex√©cutions d'un task graph

---

### Ex√©cution manuelle

```sql
-- Force le d√©clenchement imm√©diat sans attendre le planning
-- Snowflake d√©clenche la root task, puis toutes les enfants en cascade
EXECUTE TASK raw.data_quality_task;
```

> üí° Tr√®s utile pour tester un nouveau DAG sans attendre la prochaine heure planifi√©e.

### Consulter l'historique d'ex√©cution

```sql
-- Historique des tasks de la derni√®re heure
SELECT *
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY SCHEDULED_TIME DESC;
```

**Colonnes cl√©s √† surveiller :**

| Colonne | Ce qu'elle indique |
|---|---|
| `NAME` | Nom de la task |
| `STATE` | `SUCCEEDED` / `FAILED` / `RUNNING` / `SKIPPED` |
| `SCHEDULED_TIME` | Quand la task √©tait cens√©e s'ex√©cuter |
| `QUERY_START_TIME` | Quand elle a r√©ellement d√©marr√© |
| `COMPLETED_TIME` | Quand elle a termin√© |
| `ERROR_MESSAGE` | D√©tail de l'erreur si `STATE = FAILED` |
| `GRAPH_RUN_GROUP_ID` | ID unique du run complet du DAG |

### D√©bugger une erreur dans une task

```sql
-- √âtape 1 : trouver les tasks en √©chec
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE state = 'FAILED'
  AND schema_name = 'RAW';

-- √âtape 2 : v√©rifier les logs de la table raw.logging
SELECT *
FROM raw.logging
WHERE error_message IS NOT NULL
ORDER BY created_at DESC;

-- √âtape 3 : lister toutes les tasks et leur statut actuel
SHOW TASKS IN SCHEMA HEALTH_APP.RAW;
```

---

## 3 ¬∑ Comportement des tasks en cas de bug

### Objectifs de cette section
- Comprendre le comportement par d√©faut en cas d'erreur
- Savoir quand utiliser l'option `RETRY LAST`
- Comprendre l'int√©r√™t de d√©coupler la d√©finition des tasks de la logique de transformation

---

### Comportement par d√©faut

Quand une task **enfant** √©choue dans un DAG :
- Elle est marqu√©e `FAILED` dans `TASK_HISTORY`
- Les autres tasks enfants (parall√®les) **continuent quand m√™me**
- La root task du prochain run repart **depuis le d√©but**

```
Run #1 : data_quality_task ‚Üí OK
         ‚îú‚îÄ‚îÄ hih_listener_manager  ‚Üí ‚úÖ OK
         ‚îú‚îÄ‚îÄ step_lsc              ‚Üí ‚ùå FAILED
         ‚îî‚îÄ‚îÄ step_screenutil       ‚Üí ‚úÖ OK  (continue malgr√© l'√©chec de step_lsc)

Run #2 (automatique) : repart depuis data_quality_task (tout recommence)
```

### L'option `RETRY LAST`

Permet de **relancer uniquement les tasks qui ont √©chou√©** lors du dernier run, sans tout relancer depuis le d√©but.

```sql
-- Relancer uniquement les tasks FAILED du dernier run
EXECUTE TASK raw.data_quality_task RETRY LAST;
```

**Quand l'utiliser ?**
- Quand le probl√®me √©tait temporaire (r√©seau, warehouse suspendu‚Ä¶)
- Quand les tasks qui ont r√©ussi ne doivent pas √™tre re-ex√©cut√©es (ex : √©viter les doublons)
- Quand le DAG est long et que relancer tout depuis le d√©but est co√ªteux

### D√©coupler la d√©finition des tasks de la logique

**Mauvaise pratique ‚ùå ‚Äî logique dans la task directement**

```sql
CREATE OR ALTER TASK raw.step_lsc
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task
AS
    -- toute la logique est ici : difficile √† tester, √† r√©utiliser, √† d√©bugger
    INSERT INTO staging.step_lsc (event_timestamp, process_id, log_trigger, message)
    SELECT re.event_timestamp, re.process_id, ...
    FROM raw.raw_events re
    LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
    WHERE re.process_name = 'Step_LSC'
      AND da.event_id IS NULL;
```

**Bonne pratique ‚úÖ ‚Äî logique dans une proc√©dure, task = planificateur**

```sql
-- La proc√©dure contient la logique (testable avec CALL ind√©pendamment)
CREATE OR REPLACE PROCEDURE raw.enrich_data(table_name STRING, process_name STRING, run_id STRING)
    ...

-- La task ne fait QUE d√©clencher la proc√©dure
CREATE OR ALTER TASK raw.step_lsc
    WAREHOUSE = COMPUTE_WH
    AFTER raw.data_quality_task
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL raw.enrich_data('step_lsc', 'Step_LSC', :run_id);
END;
```

**Avantages du d√©couplage :**
- On peut tester la proc√©dure avec `CALL` sans d√©clencher toute la task
- La logique est r√©utilisable dans d'autres contextes
- Plus facile √† d√©bugger (on isole le probl√®me)
- Plus facile √† faire √©voluer (modifier la proc√©dure sans toucher √† la task)

---

## 4 ¬∑ Logging & qualit√© de la data

### Objectifs de cette section
- Mettre en place du logging dans les tasks
- D√©finir une proc√©dure pour tester la qualit√© de la data re√ßue

---

### La table de logging

```sql
CREATE OR ALTER TABLE raw.logging (
    created_at          TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
    graph_run_group_id  STRING,              -- ID unique du run complet du DAG
    table_name          STRING,              -- quelle table a √©t√© enrichie
    n_rows              NUMBER,              -- nb de lignes ins√©r√©es (NULL si erreur)
    error_message       STRING DEFAULT NULL  -- NULL si succ√®s, message si √©chec
);
```

**Comment lire les logs :**

| `n_rows` | `error_message` | Signification |
|---|---|---|
| `5842` | `NULL` | ‚úÖ Succ√®s ‚Äî 5842 lignes ins√©r√©es |
| `NULL` | `"Table not found..."` | ‚ùå √âchec ‚Äî voir le message d'erreur |
| `0` | `NULL` | ‚ö†Ô∏è Aucune donn√©e nouvelle ce run (normal) |

### La proc√©dure de logging

```sql
CREATE OR REPLACE PROCEDURE raw.log_results(
    graph_run_group_id  STRING,
    table_name          STRING,
    n_rows              NUMBER,
    error_message       STRING
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
    INSERT INTO raw.logging (graph_run_group_id, table_name, n_rows, error_message)
    VALUES (:graph_run_group_id, :table_name, :n_rows, :error_message);
$$;
```

### La proc√©dure de data quality

```sql
CREATE OR REPLACE PROCEDURE raw.data_quality(graph_run_group_id STRING)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
BEGIN
    Let nbre_lignes_incorrectes INT := 0;

    -- D√©tecte les anomalies : timestamp invalide OU process_name invalide
    INSERT INTO raw.data_anomalies (event_id, is_correct_timestamp, is_correct_process_name, graph_run_group_id)
    WITH source AS (
        SELECT
            event_id,
            raw.check_correct_timestamp(event_timestamp)   AS is_correct_timestamp,
            raw.check_correct_process_name(process_name)   AS is_correct_process_name
        FROM raw.raw_events
    )
    SELECT *, :graph_run_group_id AS graph_run_group_id
    FROM source
    WHERE is_correct_timestamp = FALSE
       OR is_correct_process_name = FALSE;

    nbre_lignes_incorrectes := SQLROWCOUNT;
    RETURN :nbre_lignes_incorrectes;
END;
$$;
```

### Le `graph_run_group_id` ‚Äî concept cl√©

```
Run du DAG #1 (10h00)
‚îú‚îÄ‚îÄ data_quality_task     ‚Üí graph_run_group_id = "abc-123"
‚îú‚îÄ‚îÄ hih_listener_manager  ‚Üí graph_run_group_id = "abc-123"  ‚Üê m√™me ID !
‚îî‚îÄ‚îÄ step_lsc              ‚Üí graph_run_group_id = "abc-123"  ‚Üê m√™me ID !

Run du DAG #2 (11h00)
‚îú‚îÄ‚îÄ data_quality_task     ‚Üí graph_run_group_id = "xyz-456"  ‚Üê nouvel ID
‚îú‚îÄ‚îÄ hih_listener_manager  ‚Üí graph_run_group_id = "xyz-456"
‚îî‚îÄ‚îÄ step_lsc              ‚Üí graph_run_group_id = "xyz-456"
```

Cela permet de retrouver **tout ce qui s'est pass√© lors d'un run** avec un simple filtre :

```sql
SELECT * FROM raw.logging WHERE graph_run_group_id = 'abc-123';
```

---

## 5 ¬∑ Gestion des exceptions

### Objectifs de cette section
- Savoir attraper les exceptions dans Snowflake avec du SQL
- D√©finir et lancer des exceptions personnalis√©es
- Utiliser la variable `SQLERRM` pour comprendre la cause d'une exception

---

### Structure d'un bloc avec exceptions

```sql
DECLARE
    -- D√©clarer une exception personnalis√©e
    -- Syntaxe : EXCEPTION (code_erreur, 'message')
    -- Le code n√©gatif (-9999) √©vite les conflits avec les codes syst√®me Snowflake
    mon_exception EXCEPTION (-9999, 'Description de mon erreur');

BEGIN
    -- Code qui peut potentiellement √©chouer
    INSERT INTO ma_table ...;

EXCEPTION
    -- WHEN OTHER THEN = attrape TOUTES les exceptions non g√©r√©es explicitement
    WHEN OTHER THEN
        -- SQLERRM : variable syst√®me contenant le MESSAGE TEXTE de l'erreur
        -- Exemple : "Table 'STAGING.STEP_LSC' does not exist"
        LET message STRING := SQLERRM;

        -- Faire quelque chose avec l'erreur (ex: logger)
        INSERT INTO raw.logging (error_message) VALUES (:message);

        -- RAISE : re-propage l'exception vers l'appelant
        -- Sans RAISE, l'erreur est "aval√©e" et l'appelant croit que tout s'est bien pass√©
        RAISE mon_exception;

END;
```

### Les 3 variables syst√®me √† conna√Ætre

| Variable | Type | Contient | Disponible |
|---|---|---|---|
| `SQLROWCOUNT` | Automatique | Nb de lignes affect√©es par le dernier DML | Apr√®s chaque INSERT/UPDATE/DELETE |
| `SQLERRM` | Contexte d'erreur | Message texte de l'erreur | Dans le bloc `EXCEPTION` uniquement |
| `SQLCODE` | Contexte d'erreur | Code num√©rique de l'erreur | Dans le bloc `EXCEPTION` uniquement |

### Exemple complet ‚Äî `enrich_data` avec exceptions

```sql
CREATE OR REPLACE PROCEDURE raw.enrich_data(
    table_name          STRING,
    process_name        STRING,
    graph_run_group_id  STRING
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
DECLARE
    full_table_name  STRING := CONCAT('staging.', :table_name);
    insert_exception EXCEPTION (-9999, 'Exception in data loading into staging tables');

BEGIN
    Let n_rows INT := 0;

    INSERT INTO IDENTIFIER(:full_table_name) (event_timestamp, process_id, log_trigger, message)
    WITH source AS (
        SELECT
            re.event_timestamp,
            re.process_id,
            raw.extract_log_trigger(re.message) AS log_trigger,
            raw.extract_log_message(re.message) AS message
        FROM raw.raw_events re
        LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
        WHERE re.process_name = :process_name
          AND da.event_id IS NULL
    )
    SELECT event_timestamp, process_id, log_trigger, message
    FROM source;

    n_rows := SQLROWCOUNT;

    -- Log du SUCC√àS
    CALL raw.log_results(:graph_run_group_id, :table_name, :n_rows, NULL);
    RETURN :n_rows;

EXCEPTION
    WHEN OTHER THEN
        -- 1. Capture le message d'erreur (SQLERRM)
        -- 2. Log l'√âCHEC avant de propager
        -- 3. RAISE re-propage ‚Üí la Task est marqu√©e FAILED dans TASK_HISTORY
        CALL raw.log_results(:graph_run_group_id, :table_name, NULL, :SQLERRM);
        RAISE insert_exception;

END;
$$;
```

### Flux de gestion d'erreur visualis√©

```
INSERT √©choue
      ‚îÇ
      ‚ñº
WHEN OTHER THEN
      ‚îÇ
      ‚îú‚îÄ‚Üí SQLERRM  ‚Üí  "Table STAGING.STEP_LSC does not exist"
      ‚îÇ
      ‚îú‚îÄ‚Üí log_results(NULL, SQLERRM)
      ‚îÇ          ‚Üì
      ‚îÇ     raw.logging:
      ‚îÇ     n_rows        = NULL
      ‚îÇ     error_message = "Table STAGING.STEP_LSC does not exist"
      ‚îÇ
      ‚îî‚îÄ‚Üí RAISE insert_exception
                 ‚Üì
           Task Snowflake ‚Üí STATE = FAILED
                 ‚Üì
           Visible dans TASK_HISTORY avec error_message
```

---

## 6 ¬∑ Introduction aux Streams

### Objectifs de cette section
- Comprendre le concept de Stream
- Savoir d√©finir un stream
- Comprendre les propri√©t√©s des streams

---

### Qu'est-ce qu'un Stream ?

Un **Stream** est un objet Snowflake qui **capture les changements** (INSERT, UPDATE, DELETE) survenus sur une table depuis la derni√®re fois qu'il a √©t√© lu. C'est un m√©canisme de **Change Data Capture (CDC)**.

```
Table raw_events
‚îÇ
‚îÇ  nouvelles lignes ins√©r√©es ‚Üí  [ ligne A ]
‚îÇ                                [ ligne B ]
‚îÇ
‚ñº
Stream raw_events_stream
‚Üí contient uniquement les lignes NOUVELLES ou MODIFI√âES depuis la derni√®re lecture
```

### Cr√©er un Stream

```sql
-- Stream sur une table (capture les INSERTs, UPDATEs, DELETEs)
CREATE OR REPLACE STREAM raw.raw_events_stream
    ON TABLE raw.raw_events;

-- Stream append-only (capture uniquement les INSERTs ‚Äî plus l√©ger)
CREATE OR REPLACE STREAM raw.raw_events_stream
    ON TABLE raw.raw_events
    APPEND_ONLY = TRUE;   -- recommand√© si la table ne re√ßoit que des INSERT
```

### Propri√©t√©s et colonnes sp√©ciales d'un Stream

Quand tu lis un stream, des colonnes suppl√©mentaires sont disponibles :

| Colonne | Type | Contient |
|---|---|---|
| `METADATA$ACTION` | STRING | `INSERT` ou `DELETE` |
| `METADATA$ISUPDATE` | BOOLEAN | `TRUE` si c'est la partie UPDATE d'un changement |
| `METADATA$ROW_ID` | STRING | Identifiant unique de la ligne dans le stream |

```sql
-- Lire les nouvelles donn√©es d'un stream
SELECT
    event_id,
    event_timestamp,
    process_name,
    METADATA$ACTION    AS action,         -- 'INSERT' ou 'DELETE'
    METADATA$ISUPDATE  AS is_update
FROM raw.raw_events_stream;
```

### Comportement important √† conna√Ætre

> ‚ö†Ô∏è **Un stream est consomm√© quand on le lit dans une transaction DML (INSERT, UPDATE, DELETE, MERGE).** Un simple `SELECT` ne consomme PAS le stream.

```sql
-- ‚ùå Ne consomme PAS le stream
SELECT * FROM raw.raw_events_stream;

-- ‚úÖ Consomme le stream (les donn√©es lues disparaissent du stream)
INSERT INTO staging.raw_events_copy
SELECT * FROM raw.raw_events_stream;
```

### V√©rifier si un stream a des donn√©es

```sql
-- Retourne TRUE si le stream contient des donn√©es non consomm√©es
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream');
```

---

## 7 ¬∑ Cr√©er des tasks "Event Driven"

### Objectifs de cette section
- Comprendre l'int√©r√™t d'une architecture r√©active
- Utiliser la fonction `SYSTEM$STREAMHASDATA`
- D√©bugger des tasks event-driven

---

### Architecture planifi√©e vs r√©active

**Architecture planifi√©e (Schedule) :**
```
Toutes les heures ‚Üí  Task s'ex√©cute
                      Si donn√©es : traite
                      Si pas de donn√©es : inutile mais consomme quand m√™me le warehouse
```

**Architecture r√©active (Event Driven) :**
```
Nouvelles donn√©es dans le stream ‚Üí  Task se d√©clenche automatiquement
                                      Traite uniquement s'il y a quelque chose √† faire
                                      Pas d'ex√©cution inutile ‚Üí √©conomie de cr√©dits
```

### Cr√©er une task d√©clench√©e par un stream

```sql
-- Root task avec SCHEDULE + condition WHEN
CREATE OR ALTER TASK raw.data_quality_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 MINUTES'   -- v√©rifie toutes les minutes s'il y a des donn√©es
    WHEN SYSTEM$STREAMHASDATA('raw.raw_events_stream')  -- ‚Üê ne s'ex√©cute QUE s'il y a des donn√©es
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL raw.data_quality(:run_id);
END;
```

> üí° **Astuce** : Le `SCHEDULE` d√©finit la fr√©quence de v√©rification, pas la fr√©quence d'ex√©cution. Si `SYSTEM$STREAMHASDATA` retourne `FALSE`, la task est `SKIPPED` sans consommer de cr√©dits warehouse.

### `SYSTEM$STREAMHASDATA` expliqu√©

```sql
-- Retourne TRUE si le stream a des donn√©es non consomm√©es
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream');
-- ‚Üí TRUE  = il y a des nouvelles donn√©es √† traiter
-- ‚Üí FALSE = rien de nouveau, la task sera SKIPPED

-- Utilisation dans une task
WHEN SYSTEM$STREAMHASDATA('raw.raw_events_stream')
```

### D√©bugger une task event-driven

```sql
-- V√©rifier si les tasks sont SKIPPED (stream vide) ou FAILED
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY scheduled_time DESC;

-- STATE = 'SKIPPED' ‚Üí normal, le stream √©tait vide √† ce moment-l√†
-- STATE = 'SUCCEEDED' ‚Üí donn√©es trait√©es
-- STATE = 'FAILED' ‚Üí erreur, voir error_message

-- V√©rifier manuellement si le stream a des donn√©es
SELECT SYSTEM$STREAMHASDATA('raw.raw_events_stream');

-- Voir les donn√©es actuelles dans le stream
SELECT COUNT(*) FROM raw.raw_events_stream;
```

---

## 8 ¬∑ La task Finalizer

### Objectifs de cette section
- D√©finir une task pour faire le m√©nage √† la fin d'un DAG
- Comprendre le r√¥le et la syntaxe du Finalizer
- D√©bugger les tasks Finalizer

---

### Qu'est-ce qu'un Finalizer ?

Le **Finalizer** est une task sp√©ciale qui s'ex√©cute **toujours en dernier**, apr√®s que **toutes les tasks du DAG ont termin√©**, qu'elles aient r√©ussi ou √©chou√©.

```
identify_new_data_task
        ‚îÇ
        ‚îú‚îÄ‚îÄ hih_listener_manager  ‚úÖ
        ‚îú‚îÄ‚îÄ step_lsc              ‚ùå (√©chec)
        ‚îî‚îÄ‚îÄ step_screenutil       ‚úÖ
                ‚îÇ
                ‚îÇ (toutes termin√©es, succ√®s ou √©chec)
                ‚ñº
        [finalize_transformation]  ‚Üê s'ex√©cute TOUJOURS
```

**Usages typiques du Finalizer dans ce projet :**
- Compter les erreurs du run depuis `raw.logging`
- Enregistrer le statut global (`SUCCEEDED` / `FAILED`) dans `raw.transformation_pipeline_status`
- Nettoyer la table de staging interm√©diaire `raw.data_to_process` si tout s'est bien pass√©
- Propager une exception si des erreurs ont √©t√© d√©tect√©es

---

### Code complet ‚Äî Le Finalizer du projet `health_app`

#### √âtape 1 ‚Äî Suspendre la root task

```sql
-- Obligatoire avant toute modification du DAG
ALTER TASK raw.identify_new_data_task SUSPEND;
```

#### √âtape 2 ‚Äî Table de suivi du pipeline

```sql
-- Stocke le statut global de chaque run du DAG
-- Un enregistrement par run : d√©marr√© √†, termin√© √†, statut final
CREATE OR ALTER TABLE raw.transformation_pipeline_status (
    graph_run_group_id  STRING,     -- ID unique du run
    started_at          TIMESTAMP,  -- heure de d√©marrage (depuis la root task)
    finished_at         TIMESTAMP,  -- heure de fin (enregistr√©e par le Finalizer)
    status              STRING      -- 'SUCCEEDED' ou 'FAILED'
);
```

#### √âtape 3 ‚Äî La proc√©dure `finalize_transformation`

```sql
CREATE OR REPLACE PROCEDURE raw.finalize_transformation(
    graph_run_group_id  STRING,    -- ID du run, pass√© depuis la task
    started_at          TIMESTAMP  -- timestamp de d√©marrage de la root task
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS
$$
DECLARE
    -- Exception custom d√©clench√©e si des erreurs sont d√©tect√©es dans le run
    pipeline_exception EXCEPTION (-20002, 'Exception in the transformation pipeline');

BEGIN
    -- Initialise le compteur d'erreurs √† 0
    LET n_errors INT := 0;

    -- √âtape A : Compter les erreurs du run courant dans raw.logging
    -- error_message IS NOT NULL = une task a plant√© lors de ce run
    SELECT COUNT(*) INTO n_errors
    FROM raw.logging
    WHERE graph_run_group_id = :graph_run_group_id
      AND error_message IS NOT NULL;

    -- √âtape B : Enregistrer le statut global du run dans transformation_pipeline_status
    -- IFF(condition, valeur_si_vrai, valeur_si_faux)
    -- ‚Üí si n_errors > 0 : statut = 'FAILED'
    -- ‚Üí sinon           : statut = 'SUCCEEDED'
    INSERT INTO raw.transformation_pipeline_status (graph_run_group_id, started_at, finished_at, status)
    SELECT
        :graph_run_group_id  AS graph_run_group_id,
        :started_at          AS started_at,
        CURRENT_TIMESTAMP()  AS finished_at,
        IFF(:n_errors > 0, 'FAILED', 'SUCCEEDED');

    -- √âtape C : Nettoyage conditionnel
    -- Si aucune erreur ‚Üí on peut vider la table interm√©diaire en toute s√©curit√©
    -- Si erreurs ‚Üí on garde les donn√©es pour investigation, et on l√®ve une exception
    IF (n_errors = 0) THEN
        TRUNCATE TABLE raw.data_to_process;  -- ‚Üê nettoyage de la table interm√©diaire
    ELSE
        RAISE pipeline_exception;            -- ‚Üê propage l'erreur ‚Üí Finalizer marqu√© FAILED
    END IF;

END;
$$;
```

#### √âtape 4 ‚Äî La task Finalizer

```sql
CREATE OR ALTER TASK raw.finalize_transformation
    WAREHOUSE = COMPUTE_WH
    FINALIZE  = 'raw.identify_new_data_task'  -- ‚Üê li√© √† la root task du DAG
AS
DECLARE
    -- R√©cup√®re l'ID du run courant (partag√© par toutes les tasks du DAG)
    graph_run_group_id STRING    := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');

    -- R√©cup√®re le timestamp de d√©marrage pr√©vu de la root task
    -- Utile pour calculer la dur√©e totale du run
    started_at         TIMESTAMP := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP');
BEGIN
    CALL raw.finalize_transformation(:graph_run_group_id, :started_at);
END;
```

#### √âtape 5 ‚Äî Activation

```sql
-- Finalizer d'abord, root task EN DERNIER
ALTER TASK raw.finalize_transformation   RESUME;
ALTER TASK raw.identify_new_data_task    RESUME;  -- ‚Üê EN DERNIER
```

#### √âtape 6 ‚Äî Donn√©es de test + v√©rification

```sql
-- Nettoyer les tables pour repartir √† z√©ro (test propre)
TRUNCATE TABLE raw.raw_events;
TRUNCATE TABLE staging.step_lsc;

-- Ins√©rer une ligne de test dans raw_events
INSERT INTO raw.raw_events (event_timestamp, process_name, process_id, message)
VALUES ('2018-12-23 22:15:29.606'::TIMESTAMP, 'Step_LSC', 30002312, 'onStandStepChanged 3579');

-- V√©rifier l'historique des tasks (derni√®re heure)
SELECT *
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW';

-- V√©rifier les logs d'enrichissement
SELECT *
FROM raw.logging
ORDER BY created_at DESC;
```

---

### Flux complet du Finalizer ‚Äî visualis√©

```
Toutes les tasks enfants ont termin√©
              ‚îÇ
              ‚ñº
  raw.finalize_transformation (task)
              ‚îÇ
              ‚ñº
  raw.finalize_transformation (proc√©dure)
              ‚îÇ
              ‚îú‚îÄ COUNT erreurs dans raw.logging
              ‚îÇ         ‚îÇ
              ‚îÇ    n_errors = 0 ?
              ‚îÇ         ‚îÇ
              ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   OUI       NON
              ‚îÇ    ‚îÇ         ‚îÇ
              ‚îÇ    ‚ñº         ‚ñº
              ‚îÇ  TRUNCATE   RAISE
              ‚îÇ  data_to_   pipeline_
              ‚îÇ  process    exception
              ‚îÇ    ‚îÇ         ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
  raw.transformation_pipeline_status
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ graph_run_group_id ‚îÇ started_at ‚îÇ finished_at ‚îÇ status ‚îÇ
  ‚îÇ "abc-123"          ‚îÇ 10:00:00   ‚îÇ 10:02:34    ‚îÇ SUCCEEDED ‚îÇ
  ‚îÇ "xyz-456"          ‚îÇ 11:00:00   ‚îÇ 11:03:01    ‚îÇ FAILED    ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### La fonction `SYSTEM$TASK_RUNTIME_INFO` ‚Äî les param√®tres utiles

| Param√®tre | Type retourn√© | Contient |
|---|---|---|
| `'CURRENT_TASK_GRAPH_RUN_GROUP_ID'` | STRING | ID unique du run complet du DAG |
| `'CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP'` | TIMESTAMP | Timestamp pr√©vu de d√©marrage de la root task |
| `'CURRENT_TASK_NAME'` | STRING | Nom complet de la task en cours d'ex√©cution |

> üí° `CURRENT_TASK_GRAPH_ORIGINAL_SCHEDULED_TIMESTAMP` est particuli√®rement utile dans le Finalizer pour calculer la **dur√©e totale du run** : `finished_at - started_at`.

---

### Diff√©rence `AFTER` vs `FINALIZE`

| `AFTER` | `FINALIZE` |
|---|---|
| S'ex√©cute apr√®s UNE task sp√©cifique | S'ex√©cute apr√®s TOUTES les tasks du DAG |
| Ne s'ex√©cute pas si la task parente a √©chou√© | S'ex√©cute TOUJOURS (succ√®s ou √©chec) |
| Plusieurs tasks peuvent avoir le m√™me `AFTER` | Un seul Finalizer par DAG |
| Task enfant normale | Task sp√©ciale de cl√¥ture |

### D√©bugger le Finalizer

```sql
-- V√©rifier que le Finalizer s'est ex√©cut√© en dernier
SELECT name, state, scheduled_time, completed_time, error_message
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -1, current_timestamp())
))
WHERE schema_name = 'RAW'
ORDER BY completed_time DESC;
-- Le Finalizer doit appara√Ætre avec le COMPLETED_TIME le plus tardif

-- V√©rifier le statut global enregistr√© par le Finalizer
SELECT *
FROM raw.transformation_pipeline_status
ORDER BY finished_at DESC;
```

---

## 9 ¬∑ Architecture du projet health_app

### Vue d'ensemble du pipeline complet

```
raw.raw_events (donn√©es brutes)
        ‚îÇ
        ‚ñº
[data_quality_task] ‚Üê toutes les heures (ou event-driven)
        ‚îÇ  Appelle raw.data_quality()
        ‚îÇ  Ins√®re les anomalies dans raw.data_anomalies
        ‚îÇ
        ‚îú‚îÄ‚îÄ [hih_listener_manager]        ‚Üí staging."HiH_ListenerManager"
        ‚îú‚îÄ‚îÄ [hih_hibroadcastutil]         ‚Üí staging."HiH_HiBroadcastUtil"
        ‚îú‚îÄ‚îÄ [step_standstepcounter]       ‚Üí staging."Step_StandStepCounter"
        ‚îú‚îÄ‚îÄ [step_sputils]               ‚Üí staging."Step_SPUtils"
        ‚îú‚îÄ‚îÄ [step_lsc]                   ‚Üí staging."Step_LSC"
        ‚îú‚îÄ‚îÄ [hih_hihealthdatainsertstore] ‚Üí staging."HiH_HiHealthDataInsertStore"
        ‚îú‚îÄ‚îÄ [hih_datastatmanager]         ‚Üí staging."HiH_DataStatManager"
        ‚îú‚îÄ‚îÄ [hih_hisyncutil]             ‚Üí staging."HiH_HiSyncUtil"
        ‚îú‚îÄ‚îÄ [step_standreportreceiver]   ‚Üí staging."Step_StandReportReceiver"
        ‚îî‚îÄ‚îÄ [step_screenutil]            ‚Üí staging."Step_ScreenUtil"
                ‚îÇ  (toutes en PARALL√àLE)
                ‚îÇ  Chacune appelle raw.enrich_data()
                ‚îÇ  Chacune logue dans raw.logging
                ‚ñº
        [finalize_transformation] ‚Üê s'ex√©cute TOUJOURS en dernier
                ‚îÇ
                ‚ñº
        raw.logging (tra√ßabilit√© compl√®te)
```

### Les tables du projet

#### `raw.raw_events` ‚Äî Source brute

```
event_id        : identifiant unique de l'√©v√©nement
event_timestamp : date/heure de l'√©v√©nement
process_name    : source applicative (ex: 'HiH_ListenerManager')
process_id      : identifiant du process
message         : message brut (contient log_trigger + message r√©el concat√©n√©s)
```

#### `raw.data_anomalies` ‚Äî Quarantaine

```sql
CREATE OR ALTER TABLE raw.data_anomalies (
    event_id                INT,
    is_correct_timestamp    BOOLEAN,  -- FALSE si timestamp invalide
    is_correct_process_name BOOLEAN,  -- FALSE si process_name invalide
    created_at              TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
    graph_run_group_id      STRING
);
```

#### `raw.logging` ‚Äî Tra√ßabilit√©

```sql
CREATE OR ALTER TABLE raw.logging (
    created_at          TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
    graph_run_group_id  STRING,
    table_name          STRING,
    n_rows              NUMBER,
    error_message       STRING DEFAULT NULL
);
```

### Le LEFT JOIN anti-anomalie

```sql
-- Technique pour exclure les lignes marqu√©es comme anomalies
-- sans les supprimer de la table source

SELECT re.*
FROM raw.raw_events re
LEFT JOIN raw.data_anomalies da ON re.event_id = da.event_id
WHERE da.event_id IS NULL;  -- ‚Üê garde UNIQUEMENT les lignes sans entr√©e dans data_anomalies

-- Visualisation :
-- raw_events          data_anomalies
-- event_id=1    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ event_id=1 (anomalie !)
-- event_id=2           (pas de correspondance)
-- event_id=3    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ event_id=3 (anomalie !)
--
-- R√©sultat : uniquement event_id=2
```

### Les UDFs requises (doivent exister pr√©alablement)

| UDF | R√¥le | Signature |
|---|---|---|
| `raw.check_correct_timestamp()` | Valide le format/plage du timestamp | `(TIMESTAMP) ‚Üí BOOLEAN` |
| `raw.check_correct_process_name()` | Valide que le process_name est connu | `(STRING) ‚Üí BOOLEAN` |
| `raw.extract_log_trigger()` | Extrait le type d'√©v√©nement du message brut | `(STRING) ‚Üí STRING` |
| `raw.extract_log_message()` | Nettoie et extrait le message r√©el | `(STRING) ‚Üí STRING` |

---

## 10 ¬∑ Glossaire complet

| Terme | D√©finition |
|---|---|
| **Task** | T√¢che SQL automatis√©e dans Snowflake (planificateur) |
| **DAG** | Directed Acyclic Graph ‚Äî graphe de t√¢ches ordonn√©es sans cycle |
| **Root Task** | T√¢che principale du DAG (a un `SCHEDULE`, d√©marre tout) |
| **Child Task** | T√¢che enfant d√©clench√©e apr√®s une autre (a un `AFTER`) |
| **Finalizer Task** | T√¢che sp√©ciale qui s'ex√©cute apr√®s TOUTES les tasks du DAG |
| **Warehouse** | Moteur de calcul Snowflake (CPU/RAM), consomme des cr√©dits |
| **SCHEDULE** | Fr√©quence de d√©clenchement automatique |
| **AFTER** | D√©pendance ‚Äî s'ex√©cute apr√®s la task cit√©e |
| **FINALIZE** | Param√®tre d√©signant une task comme finaliseur du DAG |
| **WHEN** | Condition suppl√©mentaire pour s'ex√©cuter |
| **SUSPEND / RESUME** | D√©sactiver / activer une task |
| **RETRY LAST** | Relancer uniquement les tasks FAILED du dernier run |
| **Stream** | Objet qui capture les changements (CDC) sur une table |
| **Append-Only Stream** | Stream qui capture uniquement les INSERT (plus l√©ger) |
| **SYSTEM$STREAMHASDATA** | Fonction qui indique si un stream a des donn√©es non consomm√©es |
| **SYSTEM$TASK_RUNTIME_INFO** | Fonction exposant les infos du run en cours |
| **graph_run_group_id** | ID unique d'un run complet du DAG ‚Äî partag√© par toutes les tasks |
| **Proc√©dure stock√©e** | Bloc de code SQL nomm√© et r√©utilisable (appel√© avec `CALL`) |
| **UDF** | User Defined Function ‚Äî fonction personnalis√©e |
| **IDENTIFIER()** | Permet d'utiliser une variable STRING comme nom de table |
| **SQLROWCOUNT** | Nb de lignes affect√©es par le dernier INSERT/UPDATE/DELETE |
| **SQLERRM** | Message texte de la derni√®re erreur (disponible dans EXCEPTION) |
| **SQLCODE** | Code num√©rique de la derni√®re erreur |
| **WHEN OTHER THEN** | Intercepte toutes les exceptions non g√©r√©es |
| **RAISE** | Re-propage une exception vers l'appelant |
| **EXECUTE AS CALLER** | La proc√©dure s'ex√©cute avec les droits de l'appelant |
| **DML** | Data Manipulation Language ‚Äî INSERT, UPDATE, DELETE, MERGE |
| **DDL** | Data Definition Language ‚Äî CREATE, ALTER, DROP |
| **CDC** | Change Data Capture ‚Äî m√©canisme de capture des changements |

---

## 11 ¬∑ Checklist de d√©ploiement

### Pr√©requis

```
[ ] Les UDFs existent dans le sch√©ma raw :
    [ ] raw.check_correct_timestamp()
    [ ] raw.check_correct_process_name()
    [ ] raw.extract_log_trigger()
    [ ] raw.extract_log_message()

[ ] Les tables staging existent pour chaque process

[ ] Le warehouse COMPUTE_WH existe et est actif

[ ] Le r√¥le a les droits :
    [ ] CREATE TASK sur le sch√©ma raw
    [ ] INSERT sur les tables staging
    [ ] EXECUTE sur les proc√©dures
    [ ] CREATE STREAM (si architecture event-driven)
```

### Ordre d'ex√©cution du script

```
[ ] 1.  USE ROLE / DATABASE / SCHEMA
[ ] 2.  CREATE TABLE raw.data_anomalies
[ ] 3.  CREATE TABLE raw.logging
[ ] 4.  CREATE PROCEDURE raw.log_results()
[ ] 5.  CREATE PROCEDURE raw.data_quality()
[ ] 6.  CREATE PROCEDURE raw.enrich_data()
[ ] 7.  (optionnel) CREATE STREAM raw.raw_events_stream
[ ] 8.  CREATE TASK raw.data_quality_task (root)
[ ] 9.  CREATE TASK raw.[toutes les tasks enfants]
[ ] 10. CREATE TASK raw.finalize_transformation (finalizer)
[ ] 11. ALTER TASK [toutes les enfants]        RESUME
[ ] 12. ALTER TASK raw.finalize_transformation RESUME
[ ] 13. ALTER TASK raw.data_quality_task       RESUME  ‚Üê EN DERNIER
[ ] 14. EXECUTE TASK raw.data_quality_task             ‚Üê test manuel
[ ] 15. Attendre 2-3 minutes, v√©rifier TASK_HISTORY
[ ] 16. V√©rifier raw.logging pour les r√©sultats
```

---

## 12 ¬∑ Patterns r√©utilisables

### Pattern 1 ‚Äî DAG complet avec logging et exceptions

```sql
-- Root task
CREATE OR ALTER TASK mon_schema.root_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = '1 HOURS'
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.ma_procedure_principale(:run_id);
END;

-- Child task (pattern identique pour chaque enfant)
CREATE OR ALTER TASK mon_schema.child_task
    WAREHOUSE = COMPUTE_WH
    AFTER mon_schema.root_task
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.ma_procedure_secondaire(:run_id);
END;

-- Finalizer
CREATE OR ALTER TASK mon_schema.finalizer_task
    WAREHOUSE = COMPUTE_WH
    FINALIZE = 'mon_schema.root_task'
AS
    CALL mon_schema.ma_procedure_finale();

-- Activation (ordre obligatoire)
ALTER TASK mon_schema.child_task     RESUME;
ALTER TASK mon_schema.finalizer_task RESUME;
ALTER TASK mon_schema.root_task      RESUME;  -- EN DERNIER
```

### Pattern 2 ‚Äî Task event-driven avec Stream

```sql
-- Cr√©er le stream
CREATE OR REPLACE STREAM mon_schema.ma_table_stream
    ON TABLE mon_schema.ma_table
    APPEND_ONLY = TRUE;

-- Task d√©clench√©e uniquement si le stream a des donn√©es
CREATE OR ALTER TASK mon_schema.ma_task_reactive
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = '1 MINUTES'
    WHEN SYSTEM$STREAMHASDATA('mon_schema.ma_table_stream')
AS
DECLARE
    run_id STRING := SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID');
BEGIN
    CALL mon_schema.traiter_nouvelles_donnees(:run_id);
END;
```

### Pattern 3 ‚Äî Proc√©dure avec logging et gestion d'erreur

```sql
CREATE OR REPLACE PROCEDURE mon_schema.traiter_table(
    table_name STRING,
    run_id     STRING
)
RETURNS STRING
LANGUAGE SQL
EXECUTE AS CALLER
AS $$
DECLARE
    full_table  STRING    := CONCAT('mon_staging.', :table_name);
    mon_erreur  EXCEPTION (-9999, 'Erreur lors du traitement');
BEGIN
    Let n INT := 0;

    INSERT INTO IDENTIFIER(:full_table) (col1, col2)
    SELECT col1, col2
    FROM mon_schema.ma_source
    WHERE condition = :table_name;

    n := SQLROWCOUNT;

    -- Log succ√®s
    INSERT INTO mon_schema.logs (run_id, table_name, n_rows, error_msg)
    VALUES (:run_id, :table_name, :n, NULL);

    RETURN :n;

EXCEPTION
    WHEN OTHER THEN
        -- Log √©chec + re-propagation
        INSERT INTO mon_schema.logs (run_id, table_name, n_rows, error_msg)
        VALUES (:run_id, :table_name, NULL, :SQLERRM);
        RAISE mon_erreur;

END;
$$;
```

### Pattern 4 ‚Äî Requ√™tes de monitoring standard

```sql
-- Dashboard d'un run
SELECT
    table_name,
    n_rows,
    CASE WHEN error_message IS NULL THEN '‚úÖ Succ√®s' ELSE '‚ùå √âchec' END AS statut,
    error_message
FROM raw.logging
WHERE graph_run_group_id = 'TON_RUN_ID'
ORDER BY created_at;

-- Tasks en √©chec des derni√®res 24h
SELECT name, state, error_message, scheduled_time
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    SCHEDULED_TIME_RANGE_START => DATEADD('hour', -24, current_timestamp())
))
WHERE state = 'FAILED'
  AND schema_name = 'RAW'
ORDER BY scheduled_time DESC;

-- R√©sum√© par run (nb succ√®s, nb √©checs)
SELECT
    graph_run_group_id,
    COUNT(*) AS total_tasks,
    SUM(CASE WHEN error_message IS NULL THEN 1 ELSE 0 END) AS succes,
    SUM(CASE WHEN error_message IS NOT NULL THEN 1 ELSE 0 END) AS echecs
FROM raw.logging
GROUP BY graph_run_group_id
ORDER BY MIN(created_at) DESC;
```

---

## 13 ¬∑ Conclusion du chapitre ‚Äî Architecture compl√®te

### Le sch√©ma final

Ce diagramme r√©sume l'architecture type d'un pipeline Snowflake bien construit. Chaque bloc repr√©sente une **unit√© ind√©pendante** compos√©e de 3 niveaux :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Task                 ‚îÇ  ‚Üê Planificateur (SCHEDULE ou AFTER)
‚îÇ              ‚îÇ                  ‚îÇ
‚îÇ              ‚ñº                  ‚îÇ
‚îÇ          Proc√©dure              ‚îÇ  ‚Üê Orchestrateur (logique principale)
‚îÇ           /     \               ‚îÇ
‚îÇ     Fonction   Proc√©dure        ‚îÇ  ‚Üê Briques r√©utilisables (UDFs + sous-proc√©dures)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Le pipeline global ‚Äî lecture du diagramme

```
                                         ‚îå‚îÄ‚îÄ [Task ‚Üí Proc ‚Üí Fn + Proc]
                                         ‚îÇ
[Task ‚Üí Proc ‚Üí Fn + Proc] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [Task ‚Üí Proc ‚Üí Fn + Proc] ‚îÄ‚îÄ‚ñ∫ [Task ‚Üí Proc ‚Üí Fn + Proc]
        ‚îÇ                                                             ‚îÇ
        ‚îÇ Finalize                                                    ‚îî‚îÄ‚îÄ [Task ‚Üí Proc ‚Üí Fn + Proc]
        ‚ñº
[Task ‚Üí Proc ‚Üí Fn + Proc]    ‚Üê Finalizer (s'ex√©cute toujours en dernier)
```

**Lecture :**
- Les **fl√®ches horizontales jaunes** = d√©pendances entre DAGs ou entre tasks (`AFTER`)
- La **fl√®che `Finalize`** = le Finalizer, d√©clench√© apr√®s tout le DAG principal
- Chaque **bloc gris** = une unit√© autonome Task + Proc√©dure + Fonctions/Sous-proc√©dures

---

### Les 5 principes √† retenir

**1. Toujours d√©coupler Task et logique**
> La Task ne fait que d√©clencher. La logique m√©tier vit dans la proc√©dure. On peut tester la proc√©dure ind√©pendamment avec `CALL`.

**2. La hi√©rarchie dans chaque bloc**
> `Task ‚Üí Proc√©dure ‚Üí Fonctions/Proc√©dures` ‚Äî chaque niveau a un r√¥le pr√©cis. Les UDFs (Fonctions) font des transformations atomiques, les Proc√©dures orchestrent, les Tasks planifient.

**3. Le Finalizer pour clore proprement**
> Un pipeline sans Finalizer ne sait pas quand il est vraiment "termin√©". Le Finalizer centralise le nettoyage, les notifications, et la tra√ßabilit√© de fin de run.

**4. Le logging √† chaque niveau**
> `graph_run_group_id` relie toutes les logs d'un m√™me run. On peut toujours r√©pondre √† "qu'est-ce qui s'est pass√© lors du run de 10h ?" avec un simple filtre.

**5. G√©rer les erreurs sans bloquer le pipeline**
> `WHEN OTHER THEN` + `RAISE` = on loggue l'erreur ET on la propage. La task est marqu√©e `FAILED` dans `TASK_HISTORY`, les autres tasks continuent, et on a la trace de ce qui a plant√©.

---

### R√©capitulatif des commandes essentielles

```sql
-- Cr√©er / modifier
CREATE OR ALTER TASK ...
CREATE OR REPLACE PROCEDURE ...
CREATE OR REPLACE STREAM ...

-- Cycle de vie
ALTER TASK mon_schema.ma_task SUSPEND;   -- avant modification
ALTER TASK mon_schema.ma_task RESUME;    -- apr√®s configuration

-- D√©clencher
EXECUTE TASK mon_schema.root_task;            -- run complet
EXECUTE TASK mon_schema.root_task RETRY LAST; -- relancer les FAILED uniquement

-- V√©rifier
SHOW TASKS IN SCHEMA mon_schema;
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(...));
SELECT SYSTEM$STREAMHASDATA('mon_schema.mon_stream');

-- Variables syst√®me dans les proc√©dures
SYSTEM$TASK_RUNTIME_INFO('CURRENT_TASK_GRAPH_RUN_GROUP_ID')  -- ID du run
SQLROWCOUNT   -- nb de lignes du dernier DML
SQLERRM       -- message de la derni√®re erreur (dans EXCEPTION)
```

---

*Documentation g√©n√©r√©e le 2026-02-23 ¬∑ Cours Snowflake Tasks ¬∑ Projet `health_app`*
